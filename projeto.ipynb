{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dependências do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in e:\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in e:\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in e:\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "#Instalando o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in e:\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: mouseinfo in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pymsgbox in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pyrect in e:\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in e:\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Caso não consiga pydirectinput\n",
    "%pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in e:\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in e:\\anaconda3\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.11 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.12.0)\n",
      "Requirement already satisfied: psutil in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: opencv-python in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: ale-py==0.7.4 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.3.1)\n",
      "Requirement already satisfied: importlib-resources in e:\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.5.4)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda3\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (63.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: libtorrent in e:\\anaconda3\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca de aprendizado por reforço\n",
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mss in e:\\anaconda3\\lib\\site-packages (7.0.1)\n",
      "Requirement already satisfied: pydirectinput in e:\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: pytesseract in e:\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para captura de tela\n",
    "from mss import mss\n",
    "#import pyautogui #para comandos de teclado\n",
    "import cv2 \n",
    "#Tratamentos dos frames\n",
    "import numpy as np \n",
    "import pyautogui\n",
    "#Framework intermediário paara trabalhar com as imagens\n",
    "#import pytesseract #para extrair o game over da imagem\n",
    "from matplotlib import pyplot as plt #Visualizando resultados\n",
    "import time\n",
    "from PIL import Image\n",
    "#Coisas para construir o ambinete\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete, Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import base64\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construindo o Ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe para definir o ambiente\n",
    "class WebGame(Env):\n",
    "    #ESSAS FUNÇÃO SÃO NECESSÁRIAS POR CONTA DO GYM\n",
    "    #Função responsavel pela inicialização do ambiente;\n",
    "    #Portanto onde ficam todas as variaveis do ambiente, configuração das ações e da observação \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Configuração do tempo\n",
    "        self.print_time = .005\n",
    "        self.wait_time = .015\n",
    "        \n",
    "        #Configuração do espaço\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8)\n",
    "        #self.observation_space = Dict({\n",
    "        #    \"print\":Box(low=0, high=255, shape=(1, 83,200), dtype=np.uint8),\n",
    "        #    \"score\":Box(low=0, high=10000, shape=(1,), dtype=np.uint8),\n",
    "        #                              })\n",
    "        self.action_space = Discrete(2)\n",
    "\n",
    "        #Variavei para a captura de tela\n",
    "        self.screen_cap = mss() #Lib de captura de tela\n",
    "        self.game_location = {\"top\": 300, \"left\": 0, \"width\": 650, \"height\": 500} #Área do monitor com \n",
    "        self.game_done = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 640}\n",
    "\n",
    "        self.chromedriver_path = \"./chromedriver.exe\"\n",
    "        _chrome_options = webdriver.ChromeOptions()\n",
    "        _chrome_options.add_argument(\"--mute-audio\")\n",
    "        _chrome_options.add_argument(\"--disable-gpu\")\n",
    "        self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n",
    "\n",
    "        self.last_image = np.zeros((500,650,3))\n",
    "        \n",
    "        #Dicionário de ações\n",
    "        self.action_dict = {\n",
    "            0:Keys.ARROW_UP,\n",
    "            1:'nothing'\n",
    "        }\n",
    "\n",
    "    #Função responsavel por passar as ações pro jogo, para fazer algo pro jogo\n",
    "    def step(self, action):\n",
    "        # Se ação escolhida for um dos botões, realizar a ação.\n",
    "        if action != 1:\n",
    "            self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(self.action_dict[int(action)])\n",
    "        \n",
    "        #Checa a próxima ação\n",
    "        observation = self.get_observation()\n",
    "        #Todas as ações tem que verificar se a ação acabou\n",
    "        done, done_cap = self.get_done() \n",
    "        \n",
    "        #Pegando o score do jogo\n",
    "        score = self.get_score()\n",
    "        #Ganhamos 1 ponto por cada frame que estamos vivos.\n",
    "        reward = 1\n",
    "        #É um dicionário de informações que retornam através do que a gente precisa\n",
    "        info = {\n",
    "            'score':score\n",
    "        }\n",
    "\n",
    "        time.sleep(self.wait_time)\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "        \n",
    "\n",
    "    #Função para a visualização do jogo:\n",
    "    def render(self, mode: str='human'):\n",
    "        img = cv2.cvtColor(self._get_image(), cv2.COLOR_BGR2RGB)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "        # cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     self.close()\n",
    "\n",
    "    #Função responsavel por recomeçar o jogo\n",
    "    def reset(self):\n",
    "        #Try catch precisa existir pq toda a vez q o selenium detecta que ele viu o chrome dino,\n",
    "        #ele dispara um erro que esta sem internet.\n",
    "        try:\n",
    "            self._driver.get('chrome://dino')\n",
    "            \n",
    "        except WebDriverException:\n",
    "            pass\n",
    "        WebDriverWait(self._driver, 10).until(\n",
    "            EC.presence_of_element_located((\n",
    "                By.CLASS_NAME, \n",
    "                \"runner-canvas\"\n",
    "            ))\n",
    "        )\n",
    "        self._driver.implicitly_wait(0.5)\n",
    "        self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(Keys.ARROW_UP)\n",
    "\n",
    "        return self.get_observation()\n",
    "\n",
    "    #FUNÇÕES CUSTOM\n",
    "    #Fecha a parte de visualização\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        return int(score)\n",
    "    \n",
    "    def get_score_shape(self):\n",
    "        shape = np.zeros(1)\n",
    "        shape[0] = int(self.get_score())\n",
    "        return shape\n",
    "    \n",
    "    def get_img(self):\n",
    "        LEADING_TEXT = \"data:image/png;base64,\"\n",
    "        canvas = self._driver.execute_script(\"return document.querySelector('canvas.runner-canvas').toDataURL()\")\n",
    "        img = canvas[len(LEADING_TEXT):]\n",
    "        img_data = np.array(Image.open(BytesIO(base64.b64decode(img))))\n",
    "        return img_data \n",
    "        # img = self._driver.execute_script()\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_print(self): \n",
    "\n",
    "        #img = numpy.array(self.screen_cap.grab(game_location))[:,:,3].astype(np.uint8)\n",
    "        raw = np.array(self.get_img())[:,:,:3].astype(np.uint8)\n",
    "        img = raw[:200,:400]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (200,83))\n",
    "        channel = np.reshape(resized, (1, 83,200))\n",
    "        self.last_image = raw\n",
    "        \n",
    "        return channel\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_observation(self): \n",
    "        #return {\"print\":self.get_print(), \"score\":self.get_score_shape() }\n",
    "        return self.get_print()\n",
    "\n",
    "\n",
    "    #Função para pegar o texto de fim de jogo:\n",
    "    def get_done(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\"), self.last_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EventCallback\n",
    "# Verificando se o ambiente é válido para fazer as coisa\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, SubprocVecEnv, VecNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack,SubprocVecEnv\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.logger import Figure, configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    env = Monitor(WebGame())\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecFrameStack(env, 4, channels_order='first')\n",
    "    #env = VecNormalize(env, norm_obs=True, norm_reward=True,\n",
    "    #               clip_obs=10.)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_10744\\1369848812.py:30: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#env_lambda = lambda: WebGame()\n",
    "#env2 = SubprocVecEnv([env_lambda for i in range(4)])\n",
    "env2 = get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criandos as pastas para que funcione.\n",
    "CHECKPOINT_DIR = './checkpoints/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o modelo em uma pasta chamado de treino\n",
    "import os\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.logger import Logger\n",
    "\n",
    "from stable_baselines3.common import base_class  # pytype: disable=pyi-error\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnv, sync_envs_normalization\n",
    "\n",
    "class EvalCallbackButBetter(EventCallback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: Union[gym.Env, VecEnv],\n",
    "        callback_on_new_best: Optional[BaseCallback] = None,\n",
    "        callback_after_eval: Optional[BaseCallback] = None,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        log_path: Optional[str] = None,\n",
    "        best_model_save_path: Optional[str] = None,\n",
    "        deterministic: bool = True,\n",
    "        render: bool = False,\n",
    "        verbose: int = 1,\n",
    "        warn: bool = True,\n",
    "    ):\n",
    "        super().__init__(callback_after_eval, verbose=verbose)\n",
    "\n",
    "        self.callback_on_new_best = callback_on_new_best\n",
    "        if self.callback_on_new_best is not None:\n",
    "            # Give access to the parent\n",
    "            self.callback_on_new_best.parent = self\n",
    "\n",
    "        self.n_eval_episodes = n_eval_episodes\n",
    "        self.eval_freq = eval_freq\n",
    "        self.best_mean_reward = -np.inf\n",
    "        self.last_mean_reward = -np.inf\n",
    "        self.deterministic = deterministic\n",
    "        self.render = render\n",
    "        self.warn = warn\n",
    "\n",
    "        # Convert to VecEnv for consistency\n",
    "        if not isinstance(eval_env, VecEnv):\n",
    "            eval_env = DummyVecEnv([lambda: eval_env])\n",
    "\n",
    "        self.eval_env = eval_env\n",
    "        self.best_model_save_path = best_model_save_path\n",
    "        # Logs will be written in ``evaluations.npz``\n",
    "        if log_path is not None:\n",
    "            log_path = os.path.join(log_path, \"evaluations\")\n",
    "        self.log_path = log_path\n",
    "        self.evaluations_results = []\n",
    "        self.evaluations_timesteps = []\n",
    "        self.evaluations_length = []\n",
    "        # For computing success rate\n",
    "        self._is_success_buffer = []\n",
    "        self.evaluations_successes = []\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Does not work in some corner cases, where the wrapper is not the same\n",
    "        if not isinstance(self.training_env, type(self.eval_env)):\n",
    "            warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
    "\n",
    "        # Create folders if needed\n",
    "        if self.best_model_save_path is not None:\n",
    "            os.makedirs(self.best_model_save_path, exist_ok=True)\n",
    "        if self.log_path is not None:\n",
    "            os.makedirs(os.path.dirname(self.log_path), exist_ok=True)\n",
    "\n",
    "        # Init callback called on new best model\n",
    "        if self.callback_on_new_best is not None:\n",
    "            self.callback_on_new_best.init_callback(self.model)\n",
    "\n",
    "    def _log_success_callback(self, locals_: Dict[str, Any], globals_: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Callback passed to the  ``evaluate_policy`` function\n",
    "        in order to log the success rate (when applicable),\n",
    "        for instance when using HER.\n",
    "        :param locals_:\n",
    "        :param globals_:\n",
    "        \"\"\"\n",
    "        info = locals_[\"info\"]\n",
    "\n",
    "        if locals_[\"done\"]:\n",
    "            maybe_is_success = info.get(\"is_success\")\n",
    "            if maybe_is_success is not None:\n",
    "                self._is_success_buffer.append(maybe_is_success)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        continue_training = True\n",
    "\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            # Sync training and eval env if there is VecNormalize\n",
    "            if self.model.get_vec_normalize_env() is not None:\n",
    "                try:\n",
    "                    sync_envs_normalization(self.training_env, self.eval_env)\n",
    "                except AttributeError as e:\n",
    "                    raise AssertionError(\n",
    "                        \"Training and eval env are not wrapped the same way, \"\n",
    "                        \"see https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html#evalcallback \"\n",
    "                        \"and warning above.\"\n",
    "                    ) from e\n",
    "\n",
    "            # Reset success rate buffer\n",
    "            self._is_success_buffer = []\n",
    "\n",
    "            episode_rewards, episode_lengths = evaluate_policy(\n",
    "                self.model,\n",
    "                self.eval_env,\n",
    "                n_eval_episodes=self.n_eval_episodes,\n",
    "                render=self.render,\n",
    "                deterministic=self.deterministic,\n",
    "                return_episode_rewards=True,\n",
    "                warn=self.warn,\n",
    "                callback=self._log_success_callback,\n",
    "            )\n",
    "\n",
    "            if self.log_path is not None:\n",
    "                self.evaluations_timesteps.append(self.num_timesteps)\n",
    "                self.evaluations_results.append(episode_rewards)\n",
    "                self.evaluations_length.append(episode_lengths)\n",
    "\n",
    "                kwargs = {}\n",
    "                # Save success log if present\n",
    "                if len(self._is_success_buffer) > 0:\n",
    "                    self.evaluations_successes.append(self._is_success_buffer)\n",
    "                    kwargs = dict(successes=self.evaluations_successes)\n",
    "\n",
    "                np.savez(\n",
    "                    self.log_path,\n",
    "                    timesteps=self.evaluations_timesteps,\n",
    "                    results=self.evaluations_results,\n",
    "                    ep_lengths=self.evaluations_length,\n",
    "                    **kwargs,\n",
    "                )\n",
    "\n",
    "            mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)\n",
    "            mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)\n",
    "            self.last_mean_reward = mean_reward\n",
    "\n",
    "            if self.verbose >= 1:\n",
    "                print(f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "                print(f\"Episode length: {mean_ep_length:.2f} +/- {std_ep_length:.2f}\")\n",
    "            # Add to current Logger\n",
    "            self.logger.record(\"eval/mean_reward\", float(mean_reward))\n",
    "            self.logger.record(\"eval/mean_ep_length\", mean_ep_length)\n",
    "\n",
    "            if len(self._is_success_buffer) > 0:\n",
    "                success_rate = np.mean(self._is_success_buffer)\n",
    "                if self.verbose >= 1:\n",
    "                    print(f\"Success rate: {100 * success_rate:.2f}%\")\n",
    "                self.logger.record(\"eval/success_rate\", success_rate)\n",
    "\n",
    "            # Dump log so the evaluation results are printed with the correct timestep\n",
    "            self.logger.record(\"time/total_timesteps\", self.num_timesteps, exclude=\"tensorboard\")\n",
    "            self.logger.dump(self.num_timesteps)\n",
    "\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                if self.verbose >= 1:\n",
    "                    print(\"New best mean reward!\")\n",
    "                if self.best_model_save_path is not None:\n",
    "                    self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))\n",
    "                    self.model.save_replay_buffer(os.path.join(self.best_model_save_path, \"best_model_buffer\"))\n",
    "                    self.model.policy.save(os.path.join(self.best_model_save_path, \"best_policy\"))\n",
    "                    #self.model.get_env().env_method(\"save\", [os.path.join(self.best_model_save_path, \"best_model_env\")])      \n",
    "                    \n",
    "                self.best_mean_reward = mean_reward\n",
    "                # Trigger callback on new best model, if needed\n",
    "                if self.callback_on_new_best is not None:\n",
    "                    continue_training = self.callback_on_new_best.on_step()\n",
    "\n",
    "            # Trigger callback after every evaluation, if needed\n",
    "            if self.callback is not None:\n",
    "                continue_training = continue_training and self._on_event()\n",
    "\n",
    "        return continue_training\n",
    "\n",
    "    def update_child_locals(self, locals_: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Update the references to the local variables.\n",
    "        :param locals_: the local variables during rollout collection\n",
    "        \"\"\"\n",
    "        if self.callback:\n",
    "            self.callback.update_locals(locals_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EvalCallbackButBetter(eval_env=env2, verbose=2, best_model_save_path=CHECKPOINT_DIR,\n",
    "                             log_path=LOG_DIR, eval_freq=100,\n",
    "                             deterministic=True, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = PPO('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, learning_rate=0.005, verbose=2, policy_kwargs=dict(normalize_images=False))\n",
    "    model = DQN('CnnPolicy', env2, tensorboard_log=LOG_DIR, verbose=2, buffer_size=12000, \n",
    "        learning_starts=500, policy_kwargs=dict(normalize_images=False))\n",
    "    model.set_random_seed(42)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/DQN_7\n",
      "Eval num_timesteps=100, episode_reward=146.00 +/- 12.76\n",
      "Episode length: 146.00 +/- 12.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 146      |\n",
      "|    mean_reward      | 146      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0595   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=200, episode_reward=146.40 +/- 11.29\n",
      "Episode length: 146.40 +/- 11.29\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 146      |\n",
      "|    mean_reward      | 146      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200      |\n",
      "----------------------------------\n",
      "New best mean reward!\n"
     ]
    }
   ],
   "source": [
    "#Começa o treinamento\n",
    "model._last_obs = None\n",
    "model.learn(total_timesteps=1000, callback=callback, reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hiper parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biblioteca para isso\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criandos as pastas para que funcione.\n",
    "CHECKPOINT_DIR = './checkpoints/'\n",
    "LOG_DIR = './logs/'\n",
    "OPT_DIR = './opt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para tentar retornar os hiper parametros de teste e definir a função objetivo\n",
    "#ALTERAR:\n",
    "#Essa função deve ser modificada com os respectivos Hiper-Parametros desejados para teste\n",
    "def otimizar_modelo(trial):\n",
    "    return {\n",
    "        'n_steps': trial.suggest_int('n_steps', 2048,8192),\n",
    "        'gamma': trial.suggest_float('gamma', 0.8,0.999),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5,1e-4),\n",
    "        'clip_range': trial.suggest_float('clip_range', 0.1,0.4),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda', 0.8,0.99),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para testar hiper parametros\n",
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        model_params = otimizar_modelo(trial)\n",
    "        #ALTERAR:\n",
    "        # Colocar a instanciação do eventos correta.\n",
    "        env_lambda = lambda: Monitor(WebGame(), LOG_DIR)\n",
    "        env2 = SubprocVecEnv([env_lambda for i in range(4)])\n",
    "        # REVISAR:\n",
    "        # Pq eu apenas queria colocar o mean_reward no log, visto que com a função criada a gente já salva o reward com a melhor performance.\n",
    "        #Isso sou tentando fazer plotar as paradas pro tensorboard. Eu não queria salvar os modelos, pq o optuna ja faz isso.\n",
    "        checkpoint_callback = CheckpointCallback(\n",
    "            save_freq=500,\n",
    "            save_path=CHECKPOINT_DIR,\n",
    "            name_prefix=\"model_ppo_opt\", #ALTERAR\n",
    "            save_replay_buffer=True,\n",
    "            save_vecnormalize=True,\n",
    "            verbose=2\n",
    "        )\n",
    "        eval_callback = EvalCallback(env2,\n",
    "                             log_path=LOG_DIR, eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "        callback = CallbackList([checkpoint_callback, eval_callback])\n",
    "        \n",
    "        #ALTERAR:\n",
    "        #Alterar o modelo para oq precisa. A única coisa que deve se manter é o '**model_params' pois isso é responsavel para passar para os modelos os hiper parametros necessários para otimização.\n",
    "        model = PPO('CnnPolicy', env2, tensorboard_log=LOG_DIR, verbose=2,device='cpu', **model_params, policy_kwargs=dict(normalize_images=False))\n",
    "        \n",
    "        model.learn(total_timesteps=160000)\n",
    "        \n",
    "        mean_reward,_ = evaluate_policy(model,env2,n_eval_episodes=5)\n",
    "        env2.close()\n",
    "        # ALTERAR\n",
    "        # Eu não sei se vai salvar o buffer, precisaria corrigir. Mas tamo ai\n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "\n",
    "        return mean_reward\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "#Parametros:\n",
    "#Função a ser otimizada,\n",
    "#Número de tentativas de teste,\n",
    "#N_jobs: número de processos em paralelos,\n",
    "#gc_after_trials: garbage collector para que meu pc n exploda sem memória.\n",
    "study.optimize(optimize_agent, n_trials=10, n_jobs=1, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_1304\\2256387791.py:32: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Total Reward for episode 0 is 86\n",
      "Total Reward for episode 1 is 90\n",
      "Total Reward for episode 2 is 110\n",
      "Total Reward for episode 3 is 95\n",
      "Total Reward for episode 4 is 93\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.dqn.policies import CnnPolicy # Alterar caso PPO ou MultiInput\n",
    "\n",
    "env2 = WebGame()\n",
    "model = get_model()\n",
    "model.load('checkpoints/best_model') \n",
    "model.load_replay_buffer('checkpoints/best_model_buffer') \n",
    "saved_policy = CnnPolicy.load(\"checkpoints/best_policy\")\n",
    "\n",
    "# Evaluate the loaded policy\n",
    "mean_reward, std_reward = evaluate_policy(saved_policy, env2, n_eval_episodes=10, deterministic=True)\n",
    "print('mean_reward: {}'.format(mean_reward))\n",
    "print('std_reward: {}'.format(std_reward))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7592fc34b5283b67\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7592fc34b5283b67\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/PPO_29/ --host localhost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9105c753ba2e810590fbe03dc7a47b222fde04124da1bb9f952ac899bb56b210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
