{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dependências do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in e:\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in e:\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in e:\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "#Instalando o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in e:\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: mouseinfo in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pymsgbox in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pyrect in e:\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in e:\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Caso não consiga pydirectinput\n",
    "%pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in e:\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in e:\\anaconda3\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.11 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.12.0)\n",
      "Requirement already satisfied: psutil in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: opencv-python in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: ale-py==0.7.4 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.3.1)\n",
      "Requirement already satisfied: importlib-resources in e:\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.5.4)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda3\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (63.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: libtorrent in e:\\anaconda3\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca de aprendizado por reforço\n",
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mss in e:\\anaconda3\\lib\\site-packages (7.0.1)\n",
      "Requirement already satisfied: pydirectinput in e:\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: pytesseract in e:\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para captura de tela\n",
    "from mss import mss\n",
    "#import pyautogui #para comandos de teclado\n",
    "import cv2 \n",
    "#Tratamentos dos frames\n",
    "import numpy as np \n",
    "import pyautogui\n",
    "#Framework intermediário paara trabalhar com as imagens\n",
    "#import pytesseract #para extrair o game over da imagem\n",
    "from matplotlib import pyplot as plt #Visualizando resultados\n",
    "import time\n",
    "from PIL import Image\n",
    "#Coisas para construir o ambinete\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete, Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import base64\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construindo o Ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe para definir o ambiente\n",
    "class WebGame(Env):\n",
    "    #ESSAS FUNÇÃO SÃO NECESSÁRIAS POR CONTA DO GYM\n",
    "    #Função responsavel pela inicialização do ambiente;\n",
    "    #Portanto onde ficam todas as variaveis do ambiente, configuração das ações e da observação \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Configuração do tempo\n",
    "        self.print_time = .005\n",
    "        self.wait_time = .015\n",
    "        \n",
    "        #Configuração do espaço\n",
    "        #self.observation_space = Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8)\n",
    "        self.observation_space = Dict({\n",
    "            \"print\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"print2\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"print3\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            #\"print4\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"score\":Box(low=0, high=4000, shape=(1,), dtype=np.uint8),\n",
    "                                      })\n",
    "        self.action_space = Discrete(2)\n",
    "\n",
    "        #Variavei para a captura de tela\n",
    "        self.screen_cap = mss() #Lib de captura de tela\n",
    "        self.game_location = {\"top\": 300, \"left\": 0, \"width\": 650, \"height\": 500} #Área do monitor com \n",
    "        self.game_done = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 640}\n",
    "\n",
    "        self.chromedriver_path = \"./chromedriver.exe\"\n",
    "        _chrome_options = webdriver.ChromeOptions()\n",
    "        _chrome_options.add_argument(\"--mute-audio\")\n",
    "        _chrome_options.add_argument(\"--disable-gpu\")\n",
    "        self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n",
    "\n",
    "        self.first_image = np.zeros(5)\n",
    "        self.last_image = np.zeros((500,650,3))\n",
    "        \n",
    "        #Dicionário de ações\n",
    "        self.action_dict = {\n",
    "            0:Keys.ARROW_UP,\n",
    "            1:'nothing'\n",
    "        }\n",
    "\n",
    "    #Função responsavel por passar as ações pro jogo, para fazer algo pro jogo\n",
    "    def step(self, action):\n",
    "        # Se ação escolhida for um dos botões, realizar a ação.\n",
    "        if self.action_dict[int(action)] != 'nothing':\n",
    "            self._driver.find_element(By.TAG_NAME, \"body\").send_keys(self.action_dict[int(action)])\n",
    "        \n",
    "        #Checa a próxima ação\n",
    "        observation = self.get_observation()\n",
    "        #Todas as ações tem que verificar se a ação acabou\n",
    "        done, done_cap = self.get_done() \n",
    "        \n",
    "        #Pegando o score do jogo\n",
    "        score = self.get_score()\n",
    "        #Ganhamos 1 ponto por cada frame que estamos vivos.\n",
    "        reward = 1\n",
    "        #É um dicionário de informações que retornam através do que a gente precisa\n",
    "        info = {\n",
    "            'score':score\n",
    "        }\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "        \n",
    "\n",
    "    #Função para a visualização do jogo:\n",
    "    def render(self, mode: str='human'):\n",
    "        img = cv2.cvtColor(self._get_image(), cv2.COLOR_BGR2RGB)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "        # cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     self.close()\n",
    "\n",
    "    #Função responsavel por recomeçar o jogo\n",
    "    def reset(self):\n",
    "        #Try catch precisa existir pq toda a vez q o selenium detecta que ele viu o chrome dino,\n",
    "        #ele dispara um erro que esta sem internet.\n",
    "        try:\n",
    "            self._driver.get('chrome://dino')\n",
    "            \n",
    "        except WebDriverException:\n",
    "            pass\n",
    "        WebDriverWait(self._driver, 10).until(\n",
    "            EC.presence_of_element_located((\n",
    "                By.CLASS_NAME, \n",
    "                \"runner-canvas\"\n",
    "            ))\n",
    "        )\n",
    "        self._driver.implicitly_wait(0.5)\n",
    "        self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "        return self.get_observation()\n",
    "\n",
    "    #FUNÇÕES CUSTOM\n",
    "    #Fecha a parte de visualização\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        #shape = np.zeros(1)\n",
    "        #shape[0] = int(score)\n",
    "        return int(score)\n",
    "    \n",
    "    def get_score_shape(self):\n",
    "        shape = np.zeros(1)\n",
    "        shape[0] = int(self.get_score())\n",
    "        return shape\n",
    "    \n",
    "    def get_img(self):\n",
    "        LEADING_TEXT = \"data:image/png;base64,\"\n",
    "        canvas = self._driver.execute_script(\"return document.querySelector('canvas.runner-canvas').toDataURL()\")\n",
    "        img = canvas[len(LEADING_TEXT):]\n",
    "        img_data = np.array(Image.open(BytesIO(base64.b64decode(img))))\n",
    "        return img_data \n",
    "        # img = self._driver.execute_script()\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_print(self): \n",
    "\n",
    "        #img = numpy.array(self.screen_cap.grab(game_location))[:,:,3].astype(np.uint8)\n",
    "        raw = np.array(self.get_img())[:,:,:3].astype(np.uint8)\n",
    "        img = raw[:200,:400]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (200,83))\n",
    "        channel = np.reshape(resized, (1,83,200))\n",
    "        \n",
    "        self.first_image = self.last_image\n",
    "        self.last_image = raw\n",
    "        \n",
    "        return channel\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_observation(self): \n",
    "        print1 = self.get_print()\n",
    "        self._driver.implicitly_wait(self.print_time)\n",
    "        print2 = self.get_print()\n",
    "        self._driver.implicitly_wait(self.print_time)\n",
    "        return {\"print\":print1, \"print2\":print2, \"print3\":self.get_print(), \"score\":self.get_score_shape() }\n",
    "        #return self.get_print()\n",
    "\n",
    "\n",
    "    #Função para pegar o texto de fim de jogo:\n",
    "    def get_done(self):\n",
    "        #Se as duas imagens iniciais forem iguais acabou jogo\n",
    "        done = False\n",
    "        #Colando a primeira condição devido ao fator de que as formas diferentes estavam dando problema na comparação devido ao np.all\n",
    "        \n",
    "        if self.first_image.shape != self.last_image.shape:\n",
    "            return done, self.last_image\n",
    "\n",
    "        if np.all(np.equal(self.first_image, self.last_image)) and not self._driver.execute_script(\"return Runner.instance_.playing\"):\n",
    "            done = True\n",
    "        \n",
    "        return done, self.last_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback, CallbackList\n",
    "# Verificando se o ambiente é válido para fazer as coisa\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, SubprocVecEnv, VecNormalize\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.logger import Figure, configure\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    env = Monitor(WebGame())\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True,\n",
    "                   clip_obs=10.)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_4000\\3477431199.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#env_lambda = lambda: WebGame()\n",
    "#env2 = SubprocVecEnv([env_lambda for i in range(4)])\n",
    "env2 = get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('print',\n",
       "              array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       ...,\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)),\n",
       "             ('print2',\n",
       "              array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       ...,\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)),\n",
       "             ('print3',\n",
       "              array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       ...,\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.],\n",
       "                       [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)),\n",
       "             ('score', array([[0.]], dtype=float32))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criandos as pastas para que funcione.\n",
    "CHECKPOINT_DIR = './checkpoints/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=50000,\n",
    "  save_path=CHECKPOINT_DIR,\n",
    "  name_prefix=\"model\",\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    "    verbose=2\n",
    ")\n",
    "eval_callback = EvalCallback(env2, best_model_save_path=CHECKPOINT_DIR,\n",
    "                             log_path=LOG_DIR, eval_freq=2000,\n",
    "                             deterministic=True, render=False)\n",
    "callback = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = PPO('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, learning_rate=0.005, verbose=2, policy_kwargs=dict(normalize_images=False))\n",
    "    model = DQN('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, verbose=2, buffer_size=15000, \n",
    "        learning_starts=500, exploration_fraction=0.6, exploration_initial_eps=0.9, exploration_final_eps=0.05,\n",
    "                policy_kwargs=dict(normalize_images=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:564: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 5.98GB > 4.40GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/DQN_0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 30       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 3899     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00469  |\n",
      "|    n_updates        | 849      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=241.60 +/- 50.21\n",
      "Episode length: 241.60 +/- 50.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 242      |\n",
      "|    mean_reward      | 242      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00887  |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 4954     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 1113     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=243.80 +/- 25.02\n",
      "Episode length: 243.80 +/- 25.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 244      |\n",
      "|    mean_reward      | 244      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 50       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 6194     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0031   |\n",
      "|    n_updates        | 1423     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 7258     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 1689     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=260.40 +/- 77.10\n",
      "Episode length: 260.40 +/- 77.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 260      |\n",
      "|    mean_reward      | 260      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 70       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total_timesteps  | 8538     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 2009     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total_timesteps  | 9802     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00271  |\n",
      "|    n_updates        | 2325     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=249.00 +/- 30.98\n",
      "Episode length: 249.00 +/- 30.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 249      |\n",
      "|    mean_reward      | 249      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 90       |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 551      |\n",
      "|    total_timesteps  | 11338    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 2709     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=247.00 +/- 17.78\n",
      "Episode length: 247.00 +/- 17.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 247      |\n",
      "|    mean_reward      | 247      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 637      |\n",
      "|    total_timesteps  | 12432    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 2982     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 110      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 696      |\n",
      "|    total_timesteps  | 13538    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 3259     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=221.20 +/- 35.08\n",
      "Episode length: 221.20 +/- 35.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 221      |\n",
      "|    mean_reward      | 221      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 792      |\n",
      "|    total_timesteps  | 14814    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 3578     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=16000, episode_reward=238.20 +/- 24.89\n",
      "Episode length: 238.20 +/- 24.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 238      |\n",
      "|    mean_reward      | 238      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 130      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 889      |\n",
      "|    total_timesteps  | 16102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 3900     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 955      |\n",
      "|    total_timesteps  | 17362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 4215     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=247.80 +/- 7.83\n",
      "Episode length: 247.80 +/- 7.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 248      |\n",
      "|    mean_reward      | 248      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 150      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1045     |\n",
      "|    total_timesteps  | 18550    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 4512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1110     |\n",
      "|    total_timesteps  | 19770    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 4817     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=353.00 +/- 126.20\n",
      "Episode length: 353.00 +/- 126.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 353      |\n",
      "|    mean_reward      | 353      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 170      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1211     |\n",
      "|    total_timesteps  | 20910    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 5102     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=241.20 +/- 29.61\n",
      "Episode length: 241.20 +/- 29.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 241      |\n",
      "|    mean_reward      | 241      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1302     |\n",
      "|    total_timesteps  | 22106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00205  |\n",
      "|    n_updates        | 5401     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 190      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1365     |\n",
      "|    total_timesteps  | 23303    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 5700     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=267.20 +/- 41.16\n",
      "Episode length: 267.20 +/- 41.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 267      |\n",
      "|    mean_reward      | 267      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1466     |\n",
      "|    total_timesteps  | 24638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 6034     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 210      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1527     |\n",
      "|    total_timesteps  | 25796    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 6323     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=281.60 +/- 96.57\n",
      "Episode length: 281.60 +/- 96.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 282      |\n",
      "|    mean_reward      | 282      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000636 |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1631     |\n",
      "|    total_timesteps  | 27119    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 6654     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=28000, episode_reward=266.60 +/- 61.04\n",
      "Episode length: 266.60 +/- 61.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 267      |\n",
      "|    mean_reward      | 267      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 230      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1735     |\n",
      "|    total_timesteps  | 28470    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000972 |\n",
      "|    n_updates        | 6992     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1803     |\n",
      "|    total_timesteps  | 29763    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 7315     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=277.20 +/- 38.43\n",
      "Episode length: 277.20 +/- 38.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 277      |\n",
      "|    mean_reward      | 277      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 250      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1901     |\n",
      "|    total_timesteps  | 30978    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 7619     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=257.80 +/- 21.67\n",
      "Episode length: 257.80 +/- 21.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 258      |\n",
      "|    mean_reward      | 258      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000897 |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 1989     |\n",
      "|    total_timesteps  | 32122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 7905     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 270      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2048     |\n",
      "|    total_timesteps  | 33242    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 8185     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=235.80 +/- 22.87\n",
      "Episode length: 235.80 +/- 22.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 236      |\n",
      "|    mean_reward      | 236      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2135     |\n",
      "|    total_timesteps  | 34322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 8455     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 290      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2192     |\n",
      "|    total_timesteps  | 35397    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 8723     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=255.60 +/- 31.56\n",
      "Episode length: 255.60 +/- 31.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 256      |\n",
      "|    mean_reward      | 256      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000925 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2284     |\n",
      "|    total_timesteps  | 36554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000538 |\n",
      "|    n_updates        | 9013     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    episodes         | 310      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2344     |\n",
      "|    total_timesteps  | 37682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000889 |\n",
      "|    n_updates        | 9295     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=221.60 +/- 30.32\n",
      "Episode length: 221.60 +/- 30.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 222      |\n",
      "|    mean_reward      | 222      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2438     |\n",
      "|    total_timesteps  | 38926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000689 |\n",
      "|    n_updates        | 9606     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40000, episode_reward=222.00 +/- 14.01\n",
      "Episode length: 222.00 +/- 14.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 222      |\n",
      "|    mean_reward      | 222      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000704 |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 330      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2528     |\n",
      "|    total_timesteps  | 40122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 9905     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2591     |\n",
      "|    total_timesteps  | 41314    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00423  |\n",
      "|    n_updates        | 10203    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=232.60 +/- 35.52\n",
      "Episode length: 232.60 +/- 35.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 233      |\n",
      "|    mean_reward      | 233      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 350      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2681     |\n",
      "|    total_timesteps  | 42430    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 10482    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2743     |\n",
      "|    total_timesteps  | 43594    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000947 |\n",
      "|    n_updates        | 10773    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=277.40 +/- 52.45\n",
      "Episode length: 277.40 +/- 52.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 277      |\n",
      "|    mean_reward      | 277      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 370      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2839     |\n",
      "|    total_timesteps  | 44784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000494 |\n",
      "|    n_updates        | 11070    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=265.00 +/- 20.33\n",
      "Episode length: 265.00 +/- 20.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 265      |\n",
      "|    mean_reward      | 265      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 2941     |\n",
      "|    total_timesteps  | 46206    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 11426    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 390      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3002     |\n",
      "|    total_timesteps  | 47341    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000956 |\n",
      "|    n_updates        | 11709    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=245.20 +/- 42.78\n",
      "Episode length: 245.20 +/- 42.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 245      |\n",
      "|    mean_reward      | 245      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000533 |\n",
      "|    n_updates        | 11874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3106     |\n",
      "|    total_timesteps  | 48710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000883 |\n",
      "|    n_updates        | 12052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 410      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3162     |\n",
      "|    total_timesteps  | 49758    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 12314    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_50000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_50000_steps.pkl\n",
      "Saving model VecNormalize to ./checkpoints/model_vecnormalize_50000_steps.pkl\n",
      "Eval num_timesteps=50000, episode_reward=233.60 +/- 20.30\n",
      "Episode length: 233.60 +/- 20.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 234      |\n",
      "|    mean_reward      | 234      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000597 |\n",
      "|    n_updates        | 12374    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3292     |\n",
      "|    total_timesteps  | 50807    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 12576    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 430      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3355     |\n",
      "|    total_timesteps  | 51823    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 12830    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=235.40 +/- 60.90\n",
      "Episode length: 235.40 +/- 60.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 235      |\n",
      "|    mean_reward      | 235      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 52000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 12874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3444     |\n",
      "|    total_timesteps  | 52845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000842 |\n",
      "|    n_updates        | 13085    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 450      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3510     |\n",
      "|    total_timesteps  | 53978    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000459 |\n",
      "|    n_updates        | 13369    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=258.40 +/- 106.37\n",
      "Episode length: 258.40 +/- 106.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 258      |\n",
      "|    mean_reward      | 258      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 54000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 13374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3608     |\n",
      "|    total_timesteps  | 55051    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00155  |\n",
      "|    n_updates        | 13637    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=258.40 +/- 61.10\n",
      "Episode length: 258.40 +/- 61.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 258      |\n",
      "|    mean_reward      | 258      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 56000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000549 |\n",
      "|    n_updates        | 13874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 470      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3709     |\n",
      "|    total_timesteps  | 56226    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00061  |\n",
      "|    n_updates        | 13931    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3769     |\n",
      "|    total_timesteps  | 57258    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000465 |\n",
      "|    n_updates        | 14189    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=273.00 +/- 53.45\n",
      "Episode length: 273.00 +/- 53.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 273      |\n",
      "|    mean_reward      | 273      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 58000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000638 |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 490      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3872     |\n",
      "|    total_timesteps  | 58474    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 14493    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 3934     |\n",
      "|    total_timesteps  | 59530    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 14757    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=251.00 +/- 25.90\n",
      "Episode length: 251.00 +/- 25.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 251      |\n",
      "|    mean_reward      | 251      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000972 |\n",
      "|    n_updates        | 14874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 510      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4040     |\n",
      "|    total_timesteps  | 60834    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 15083    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4101     |\n",
      "|    total_timesteps  | 61898    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 15349    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=62000, episode_reward=234.00 +/- 11.51\n",
      "Episode length: 234.00 +/- 11.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 234      |\n",
      "|    mean_reward      | 234      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 62000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 15374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 530      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4195     |\n",
      "|    total_timesteps  | 62974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000759 |\n",
      "|    n_updates        | 15618    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=261.60 +/- 79.05\n",
      "Episode length: 261.60 +/- 79.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 262      |\n",
      "|    mean_reward      | 262      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 64000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00037  |\n",
      "|    n_updates        | 15874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4306     |\n",
      "|    total_timesteps  | 64246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 15936    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 550      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4368     |\n",
      "|    total_timesteps  | 65340    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000782 |\n",
      "|    n_updates        | 16209    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=310.20 +/- 54.34\n",
      "Episode length: 310.20 +/- 54.34\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 310      |\n",
      "|    mean_reward      | 310      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 66000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00066  |\n",
      "|    n_updates        | 16374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4467     |\n",
      "|    total_timesteps  | 66497    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000738 |\n",
      "|    n_updates        | 16498    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 570      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4526     |\n",
      "|    total_timesteps  | 67529    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000449 |\n",
      "|    n_updates        | 16756    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=331.40 +/- 110.16\n",
      "Episode length: 331.40 +/- 110.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 331      |\n",
      "|    mean_reward      | 331      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 68000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 16874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4636     |\n",
      "|    total_timesteps  | 68698    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000891 |\n",
      "|    n_updates        | 17049    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 590      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4698     |\n",
      "|    total_timesteps  | 69778    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 17319    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=296.80 +/- 26.32\n",
      "Episode length: 296.80 +/- 26.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 297      |\n",
      "|    mean_reward      | 297      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000981 |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4802     |\n",
      "|    total_timesteps  | 71014    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00231  |\n",
      "|    n_updates        | 17628    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=358.20 +/- 21.25\n",
      "Episode length: 358.20 +/- 21.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 358      |\n",
      "|    mean_reward      | 358      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000789 |\n",
      "|    n_updates        | 17874    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 610      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4899     |\n",
      "|    total_timesteps  | 72096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000987 |\n",
      "|    n_updates        | 17898    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 4960     |\n",
      "|    total_timesteps  | 73226    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00126  |\n",
      "|    n_updates        | 18181    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=74000, episode_reward=276.00 +/- 78.72\n",
      "Episode length: 276.00 +/- 78.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 276      |\n",
      "|    mean_reward      | 276      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 74000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000406 |\n",
      "|    n_updates        | 18374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 630      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5053     |\n",
      "|    total_timesteps  | 74301    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000837 |\n",
      "|    n_updates        | 18449    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5109     |\n",
      "|    total_timesteps  | 75346    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000387 |\n",
      "|    n_updates        | 18711    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=393.20 +/- 121.76\n",
      "Episode length: 393.20 +/- 121.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 393      |\n",
      "|    mean_reward      | 393      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 76000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 18874    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 650      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5216     |\n",
      "|    total_timesteps  | 76578    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000417 |\n",
      "|    n_updates        | 19019    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5281     |\n",
      "|    total_timesteps  | 77798    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000582 |\n",
      "|    n_updates        | 19324    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=362.40 +/- 29.80\n",
      "Episode length: 362.40 +/- 29.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 362      |\n",
      "|    mean_reward      | 362      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 78000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00032  |\n",
      "|    n_updates        | 19374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 670      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5388     |\n",
      "|    total_timesteps  | 79118    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000733 |\n",
      "|    n_updates        | 19654    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=330.40 +/- 65.96\n",
      "Episode length: 330.40 +/- 65.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 330      |\n",
      "|    mean_reward      | 330      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000366 |\n",
      "|    n_updates        | 19874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 5486     |\n",
      "|    total_timesteps  | 80260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000723 |\n",
      "|    n_updates        | 19939    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 690      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5556     |\n",
      "|    total_timesteps  | 81568    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000773 |\n",
      "|    n_updates        | 20266    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=235.00 +/- 30.53\n",
      "Episode length: 235.00 +/- 30.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 235      |\n",
      "|    mean_reward      | 235      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 82000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5655     |\n",
      "|    total_timesteps  | 82854    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000385 |\n",
      "|    n_updates        | 20588    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=223.20 +/- 31.63\n",
      "Episode length: 223.20 +/- 31.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 223      |\n",
      "|    mean_reward      | 223      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000713 |\n",
      "|    n_updates        | 20874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 710      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5757     |\n",
      "|    total_timesteps  | 84098    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 20899    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5828     |\n",
      "|    total_timesteps  | 85378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00082  |\n",
      "|    n_updates        | 21219    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=86000, episode_reward=301.80 +/- 48.18\n",
      "Episode length: 301.80 +/- 48.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 302      |\n",
      "|    mean_reward      | 302      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 86000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000866 |\n",
      "|    n_updates        | 21374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 730      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5938     |\n",
      "|    total_timesteps  | 86714    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000323 |\n",
      "|    n_updates        | 21553    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 5995     |\n",
      "|    total_timesteps  | 87762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 21815    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=423.60 +/- 203.10\n",
      "Episode length: 423.60 +/- 203.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 424      |\n",
      "|    mean_reward      | 424      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000548 |\n",
      "|    n_updates        | 21874    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 750      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6115     |\n",
      "|    total_timesteps  | 89122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00063  |\n",
      "|    n_updates        | 22155    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=275.80 +/- 17.00\n",
      "Episode length: 275.80 +/- 17.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 276      |\n",
      "|    mean_reward      | 276      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00591  |\n",
      "|    n_updates        | 22374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6229     |\n",
      "|    total_timesteps  | 90710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 22552    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 770      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6298     |\n",
      "|    total_timesteps  | 91946    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0026   |\n",
      "|    n_updates        | 22861    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=222.20 +/- 47.48\n",
      "Episode length: 222.20 +/- 47.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 222      |\n",
      "|    mean_reward      | 222      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 92000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000963 |\n",
      "|    n_updates        | 22874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6397     |\n",
      "|    total_timesteps  | 93163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000903 |\n",
      "|    n_updates        | 23165    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=301.40 +/- 45.48\n",
      "Episode length: 301.40 +/- 45.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 301      |\n",
      "|    mean_reward      | 301      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 94000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 23374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 790      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 6496     |\n",
      "|    total_timesteps  | 94378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000537 |\n",
      "|    n_updates        | 23469    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6560     |\n",
      "|    total_timesteps  | 95584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 23770    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=298.20 +/- 64.32\n",
      "Episode length: 298.20 +/- 64.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 298      |\n",
      "|    mean_reward      | 298      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 23874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 810      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6664     |\n",
      "|    total_timesteps  | 96882    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 24095    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=323.00 +/- 99.07\n",
      "Episode length: 323.00 +/- 99.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 323      |\n",
      "|    mean_reward      | 323      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 98000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 24374    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 6769     |\n",
      "|    total_timesteps  | 98218    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 24429    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 830      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6831     |\n",
      "|    total_timesteps  | 99366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 24716    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_100000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_100000_steps.pkl\n",
      "Saving model VecNormalize to ./checkpoints/model_vecnormalize_100000_steps.pkl\n",
      "Eval num_timesteps=100000, episode_reward=303.60 +/- 69.32\n",
      "Episode length: 303.60 +/- 69.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 304      |\n",
      "|    mean_reward      | 304      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 24874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 6974     |\n",
      "|    total_timesteps  | 100534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 25008    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 850      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7044     |\n",
      "|    total_timesteps  | 101786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000947 |\n",
      "|    n_updates        | 25321    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=215.20 +/- 33.73\n",
      "Episode length: 215.20 +/- 33.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 215      |\n",
      "|    mean_reward      | 215      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 102000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000996 |\n",
      "|    n_updates        | 25374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7133     |\n",
      "|    total_timesteps  | 102830   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000404 |\n",
      "|    n_updates        | 25582    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=269.20 +/- 52.40\n",
      "Episode length: 269.20 +/- 52.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 269      |\n",
      "|    mean_reward      | 269      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 104000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 25874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 870      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7243     |\n",
      "|    total_timesteps  | 104122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 25905    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7311     |\n",
      "|    total_timesteps  | 105346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000448 |\n",
      "|    n_updates        | 26211    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=220.60 +/- 6.77\n",
      "Episode length: 220.60 +/- 6.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 221      |\n",
      "|    mean_reward      | 221      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 106000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000512 |\n",
      "|    n_updates        | 26374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.305    |\n",
      "| time/               |          |\n",
      "|    episodes         | 890      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7399     |\n",
      "|    total_timesteps  | 106423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000965 |\n",
      "|    n_updates        | 26480    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7461     |\n",
      "|    total_timesteps  | 107530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 26757    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=322.80 +/- 65.22\n",
      "Episode length: 322.80 +/- 65.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 323      |\n",
      "|    mean_reward      | 323      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 108000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00083  |\n",
      "|    n_updates        | 26874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 910      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7563     |\n",
      "|    total_timesteps  | 108722   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00076  |\n",
      "|    n_updates        | 27055    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7627     |\n",
      "|    total_timesteps  | 109873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000482 |\n",
      "|    n_updates        | 27342    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=270.00 +/- 43.51\n",
      "Episode length: 270.00 +/- 43.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 270      |\n",
      "|    mean_reward      | 270      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 110000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 27374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 930      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7729     |\n",
      "|    total_timesteps  | 111094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000682 |\n",
      "|    n_updates        | 27648    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=276.00 +/- 33.99\n",
      "Episode length: 276.00 +/- 33.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 276      |\n",
      "|    mean_reward      | 276      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 112000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 27874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7825     |\n",
      "|    total_timesteps  | 112298   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 27949    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 950      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7886     |\n",
      "|    total_timesteps  | 113406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00062  |\n",
      "|    n_updates        | 28226    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=362.80 +/- 117.53\n",
      "Episode length: 362.80 +/- 117.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 363      |\n",
      "|    mean_reward      | 363      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 114000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000614 |\n",
      "|    n_updates        | 28374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7989     |\n",
      "|    total_timesteps  | 114594   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000447 |\n",
      "|    n_updates        | 28523    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 970      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8055     |\n",
      "|    total_timesteps  | 115776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 28818    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=260.20 +/- 41.26\n",
      "Episode length: 260.20 +/- 41.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 260      |\n",
      "|    mean_reward      | 260      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.252    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 116000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00602  |\n",
      "|    n_updates        | 28874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8156     |\n",
      "|    total_timesteps  | 117078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 29144    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=259.80 +/- 59.98\n",
      "Episode length: 259.80 +/- 59.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 260      |\n",
      "|    mean_reward      | 260      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 118000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000427 |\n",
      "|    n_updates        | 29374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 990      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8266     |\n",
      "|    total_timesteps  | 118430   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000644 |\n",
      "|    n_updates        | 29482    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8334     |\n",
      "|    total_timesteps  | 119678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000958 |\n",
      "|    n_updates        | 29794    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=354.60 +/- 112.81\n",
      "Episode length: 354.60 +/- 112.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 355      |\n",
      "|    mean_reward      | 355      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 120000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000269 |\n",
      "|    n_updates        | 29874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1010     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8437     |\n",
      "|    total_timesteps  | 120820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000632 |\n",
      "|    n_updates        | 30079    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=122000, episode_reward=185.80 +/- 13.99\n",
      "Episode length: 185.80 +/- 13.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 186      |\n",
      "|    mean_reward      | 186      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 122000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 30374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8544     |\n",
      "|    total_timesteps  | 122218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000618 |\n",
      "|    n_updates        | 30429    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1030     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8613     |\n",
      "|    total_timesteps  | 123466   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 30741    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=312.20 +/- 67.36\n",
      "Episode length: 312.20 +/- 67.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 312      |\n",
      "|    mean_reward      | 312      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 124000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000307 |\n",
      "|    n_updates        | 30874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8719     |\n",
      "|    total_timesteps  | 124686   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 31046    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1050     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8785     |\n",
      "|    total_timesteps  | 125883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 31345    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=259.60 +/- 48.39\n",
      "Episode length: 259.60 +/- 48.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 260      |\n",
      "|    mean_reward      | 260      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 126000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000764 |\n",
      "|    n_updates        | 31374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8880     |\n",
      "|    total_timesteps  | 127036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 31633    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=242.40 +/- 23.80\n",
      "Episode length: 242.40 +/- 23.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 242      |\n",
      "|    mean_reward      | 242      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 128000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000865 |\n",
      "|    n_updates        | 31874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1070     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8973     |\n",
      "|    total_timesteps  | 128235   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 31933    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9035     |\n",
      "|    total_timesteps  | 129390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000186 |\n",
      "|    n_updates        | 32222    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=302.20 +/- 70.78\n",
      "Episode length: 302.20 +/- 70.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 302      |\n",
      "|    mean_reward      | 302      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 130000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 32374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1090     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9147     |\n",
      "|    total_timesteps  | 130846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 32586    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=354.40 +/- 138.99\n",
      "Episode length: 354.40 +/- 138.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 354      |\n",
      "|    mean_reward      | 354      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 132000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 32874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9255     |\n",
      "|    total_timesteps  | 132098   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000777 |\n",
      "|    n_updates        | 32899    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1110     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9318     |\n",
      "|    total_timesteps  | 133282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000658 |\n",
      "|    n_updates        | 33195    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=134000, episode_reward=259.20 +/- 44.72\n",
      "Episode length: 259.20 +/- 44.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 259      |\n",
      "|    mean_reward      | 259      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 134000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 33374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9427     |\n",
      "|    total_timesteps  | 134662   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 33540    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1130     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9495     |\n",
      "|    total_timesteps  | 135902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000257 |\n",
      "|    n_updates        | 33850    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=176.40 +/- 4.22\n",
      "Episode length: 176.40 +/- 4.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 176      |\n",
      "|    mean_reward      | 176      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 136000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000201 |\n",
      "|    n_updates        | 33874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.133    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9591     |\n",
      "|    total_timesteps  | 137202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000924 |\n",
      "|    n_updates        | 34175    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=279.00 +/- 91.53\n",
      "Episode length: 279.00 +/- 91.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 279      |\n",
      "|    mean_reward      | 279      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 138000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000927 |\n",
      "|    n_updates        | 34374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1150     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9698     |\n",
      "|    total_timesteps  | 138614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 34528    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.119    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9755     |\n",
      "|    total_timesteps  | 139698   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 34799    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=414.00 +/- 87.71\n",
      "Episode length: 414.00 +/- 87.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 414      |\n",
      "|    mean_reward      | 414      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 140000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000446 |\n",
      "|    n_updates        | 34874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.112    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1170     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9870     |\n",
      "|    total_timesteps  | 141067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00042  |\n",
      "|    n_updates        | 35141    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=427.80 +/- 144.33\n",
      "Episode length: 427.80 +/- 144.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 428      |\n",
      "|    mean_reward      | 428      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 142000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 35374    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 9984     |\n",
      "|    total_timesteps  | 142290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000667 |\n",
      "|    n_updates        | 35447    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.0974   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1190     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10052    |\n",
      "|    total_timesteps  | 143602   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 35775    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=240.80 +/- 47.48\n",
      "Episode length: 240.80 +/- 47.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 241      |\n",
      "|    mean_reward      | 241      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0951   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 144000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000185 |\n",
      "|    n_updates        | 35874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.0899   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10154    |\n",
      "|    total_timesteps  | 144938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 36109    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=318.60 +/- 68.39\n",
      "Episode length: 318.60 +/- 68.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 319      |\n",
      "|    mean_reward      | 319      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.084    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 146000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00052  |\n",
      "|    n_updates        | 36374    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.0825   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1210     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10255    |\n",
      "|    total_timesteps  | 146254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 36438    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.0757   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10322    |\n",
      "|    total_timesteps  | 147470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 36742    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=307.20 +/- 24.77\n",
      "Episode length: 307.20 +/- 24.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 307      |\n",
      "|    mean_reward      | 307      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0728   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 148000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000446 |\n",
      "|    n_updates        | 36874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.0691   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1230     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10418    |\n",
      "|    total_timesteps  | 148658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00476  |\n",
      "|    n_updates        | 37039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.0617   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10488    |\n",
      "|    total_timesteps  | 149979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0018   |\n",
      "|    n_updates        | 37369    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_150000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_150000_steps.pkl\n",
      "Saving model VecNormalize to ./checkpoints/model_vecnormalize_150000_steps.pkl\n",
      "Eval num_timesteps=150000, episode_reward=187.80 +/- 71.95\n",
      "Episode length: 187.80 +/- 71.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 188      |\n",
      "|    mean_reward      | 188      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0616   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000712 |\n",
      "|    n_updates        | 37374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.0569   |\n",
      "| time/               |          |\n",
      "|    episodes         | 1250     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10650    |\n",
      "|    total_timesteps  | 150842   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 37585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.053    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10710    |\n",
      "|    total_timesteps  | 151542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 37760    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=134.40 +/- 5.46\n",
      "Episode length: 134.40 +/- 5.46\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 134      |\n",
      "|    mean_reward      | 134      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0504   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 152000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000286 |\n",
      "|    n_updates        | 37874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1270     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10812    |\n",
      "|    total_timesteps  | 152438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000606 |\n",
      "|    n_updates        | 37984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10881    |\n",
      "|    total_timesteps  | 153264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000458 |\n",
      "|    n_updates        | 38190    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 100      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1290     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 10940    |\n",
      "|    total_timesteps  | 153960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00052  |\n",
      "|    n_updates        | 38364    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=130.40 +/- 15.05\n",
      "Episode length: 130.40 +/- 15.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 154000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000694 |\n",
      "|    n_updates        | 38374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.2     |\n",
      "|    ep_rew_mean      | 96.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11040    |\n",
      "|    total_timesteps  | 154774   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 38568    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.7     |\n",
      "|    ep_rew_mean      | 90.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1310     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11103    |\n",
      "|    total_timesteps  | 155532   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000972 |\n",
      "|    n_updates        | 38757    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=156000, episode_reward=150.20 +/- 23.65\n",
      "Episode length: 150.20 +/- 23.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 150      |\n",
      "|    mean_reward      | 150      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 156000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00339  |\n",
      "|    n_updates        | 38874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.9     |\n",
      "|    ep_rew_mean      | 85.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11198    |\n",
      "|    total_timesteps  | 156301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00094  |\n",
      "|    n_updates        | 38949    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.6     |\n",
      "|    ep_rew_mean      | 82.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1330     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11260    |\n",
      "|    total_timesteps  | 157051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 39137    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77       |\n",
      "|    ep_rew_mean      | 77       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11322    |\n",
      "|    total_timesteps  | 157817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 39328    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=147.40 +/- 46.62\n",
      "Episode length: 147.40 +/- 46.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 147      |\n",
      "|    mean_reward      | 147      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 158000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00058  |\n",
      "|    n_updates        | 39374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76.2     |\n",
      "|    ep_rew_mean      | 76.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1350     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11420    |\n",
      "|    total_timesteps  | 158626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000717 |\n",
      "|    n_updates        | 39531    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76.5     |\n",
      "|    ep_rew_mean      | 76.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11479    |\n",
      "|    total_timesteps  | 159363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 39715    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=180.40 +/- 47.68\n",
      "Episode length: 180.40 +/- 47.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 180      |\n",
      "|    mean_reward      | 180      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 160000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000731 |\n",
      "|    n_updates        | 39874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.9     |\n",
      "|    ep_rew_mean      | 75.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1370     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11581    |\n",
      "|    total_timesteps  | 160206   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 39926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.5     |\n",
      "|    ep_rew_mean      | 75.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11645    |\n",
      "|    total_timesteps  | 160995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000652 |\n",
      "|    n_updates        | 40123    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76       |\n",
      "|    ep_rew_mean      | 76       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1390     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11705    |\n",
      "|    total_timesteps  | 161742   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000627 |\n",
      "|    n_updates        | 40310    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=212.40 +/- 56.08\n",
      "Episode length: 212.40 +/- 56.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 212      |\n",
      "|    mean_reward      | 212      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 162000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 40374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 76.9     |\n",
      "|    ep_rew_mean      | 76.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11814    |\n",
      "|    total_timesteps  | 162643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 40535    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77.8     |\n",
      "|    ep_rew_mean      | 77.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1410     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11881    |\n",
      "|    total_timesteps  | 163486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 40746    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=152.20 +/- 32.22\n",
      "Episode length: 152.20 +/- 32.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 152      |\n",
      "|    mean_reward      | 152      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 164000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000569 |\n",
      "|    n_updates        | 40874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 77.9     |\n",
      "|    ep_rew_mean      | 77.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 11978    |\n",
      "|    total_timesteps  | 164282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000705 |\n",
      "|    n_updates        | 40945    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 78.7     |\n",
      "|    ep_rew_mean      | 78.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1430     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12044    |\n",
      "|    total_timesteps  | 165111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 41152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.1     |\n",
      "|    ep_rew_mean      | 79.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12109    |\n",
      "|    total_timesteps  | 165924   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 41355    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=185.20 +/- 36.99\n",
      "Episode length: 185.20 +/- 36.99\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 185      |\n",
      "|    mean_reward      | 185      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 166000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00222  |\n",
      "|    n_updates        | 41374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.1     |\n",
      "|    ep_rew_mean      | 79.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1450     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12209    |\n",
      "|    total_timesteps  | 166690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 41547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80       |\n",
      "|    ep_rew_mean      | 80       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12276    |\n",
      "|    total_timesteps  | 167510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 41752    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=182.00 +/- 46.15\n",
      "Episode length: 182.00 +/- 46.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 182      |\n",
      "|    mean_reward      | 182      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 168000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 41874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.3     |\n",
      "|    ep_rew_mean      | 79.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1470     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12366    |\n",
      "|    total_timesteps  | 168230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 41932    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.3     |\n",
      "|    ep_rew_mean      | 80.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12437    |\n",
      "|    total_timesteps  | 169112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 42152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 81.1     |\n",
      "|    ep_rew_mean      | 81.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1490     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12503    |\n",
      "|    total_timesteps  | 169940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000591 |\n",
      "|    n_updates        | 42359    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=169.20 +/- 23.50\n",
      "Episode length: 169.20 +/- 23.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 169      |\n",
      "|    mean_reward      | 169      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 170000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 42374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.8     |\n",
      "|    ep_rew_mean      | 80.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12606    |\n",
      "|    total_timesteps  | 170831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 42582    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 80.7     |\n",
      "|    ep_rew_mean      | 80.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1510     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12671    |\n",
      "|    total_timesteps  | 171670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000847 |\n",
      "|    n_updates        | 42792    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=178.40 +/- 12.92\n",
      "Episode length: 178.40 +/- 12.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 178      |\n",
      "|    mean_reward      | 178      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 172000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 42874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 81.6     |\n",
      "|    ep_rew_mean      | 81.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12772    |\n",
      "|    total_timesteps  | 172574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000649 |\n",
      "|    n_updates        | 43018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.4     |\n",
      "|    ep_rew_mean      | 82.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1530     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12840    |\n",
      "|    total_timesteps  | 173490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000274 |\n",
      "|    n_updates        | 43247    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=269.20 +/- 80.80\n",
      "Episode length: 269.20 +/- 80.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 269      |\n",
      "|    mean_reward      | 269      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 174000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 43374    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.9     |\n",
      "|    ep_rew_mean      | 84.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 12940    |\n",
      "|    total_timesteps  | 174722   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000432 |\n",
      "|    n_updates        | 43555    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.4     |\n",
      "|    ep_rew_mean      | 89.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1550     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13007    |\n",
      "|    total_timesteps  | 175932   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 43857    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=226.20 +/- 54.85\n",
      "Episode length: 226.20 +/- 54.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 226      |\n",
      "|    mean_reward      | 226      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 176000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 43874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92       |\n",
      "|    ep_rew_mean      | 92       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13103    |\n",
      "|    total_timesteps  | 177078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 44144    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=258.00 +/- 4.77\n",
      "Episode length: 258.00 +/- 4.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 258      |\n",
      "|    mean_reward      | 258      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 178000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 44374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.5     |\n",
      "|    ep_rew_mean      | 96.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1570     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13200    |\n",
      "|    total_timesteps  | 178342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000773 |\n",
      "|    n_updates        | 44460    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.2     |\n",
      "|    ep_rew_mean      | 98.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13258    |\n",
      "|    total_timesteps  | 179394   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000712 |\n",
      "|    n_updates        | 44723    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=286.40 +/- 34.66\n",
      "Episode length: 286.40 +/- 34.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 286      |\n",
      "|    mean_reward      | 286      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 180000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000993 |\n",
      "|    n_updates        | 44874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1590     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13354    |\n",
      "|    total_timesteps  | 180574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 45018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13430    |\n",
      "|    total_timesteps  | 181978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0041   |\n",
      "|    n_updates        | 45369    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=320.20 +/- 57.43\n",
      "Episode length: 320.20 +/- 57.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 320      |\n",
      "|    mean_reward      | 320      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 182000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 45374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1610     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13528    |\n",
      "|    total_timesteps  | 183186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000823 |\n",
      "|    n_updates        | 45671    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=277.80 +/- 14.12\n",
      "Episode length: 277.80 +/- 14.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 278      |\n",
      "|    mean_reward      | 278      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 184000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 45874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13627    |\n",
      "|    total_timesteps  | 184507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 46001    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1630     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13700    |\n",
      "|    total_timesteps  | 185903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 46350    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=252.80 +/- 92.20\n",
      "Episode length: 252.80 +/- 92.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 253      |\n",
      "|    mean_reward      | 253      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 186000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000779 |\n",
      "|    n_updates        | 46374    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=188000, episode_reward=269.20 +/- 63.39\n",
      "Episode length: 269.20 +/- 63.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 269      |\n",
      "|    mean_reward      | 269      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 188000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 46874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13891    |\n",
      "|    total_timesteps  | 188146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000425 |\n",
      "|    n_updates        | 46911    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1650     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 13953    |\n",
      "|    total_timesteps  | 189282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 47195    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=295.60 +/- 46.31\n",
      "Episode length: 295.60 +/- 46.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 296      |\n",
      "|    mean_reward      | 296      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 190000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 47374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14056    |\n",
      "|    total_timesteps  | 190550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 47512    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1670     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14127    |\n",
      "|    total_timesteps  | 191818   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00073  |\n",
      "|    n_updates        | 47829    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=252.20 +/- 45.44\n",
      "Episode length: 252.20 +/- 45.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 252      |\n",
      "|    mean_reward      | 252      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 192000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 47874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | 134      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14236    |\n",
      "|    total_timesteps  | 193244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 48185    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=326.80 +/- 32.91\n",
      "Episode length: 326.80 +/- 32.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 327      |\n",
      "|    mean_reward      | 327      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 194000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0057   |\n",
      "|    n_updates        | 48374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | 134      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1690     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14331    |\n",
      "|    total_timesteps  | 194365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 48465    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14391    |\n",
      "|    total_timesteps  | 195502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 48750    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=299.00 +/- 46.62\n",
      "Episode length: 299.00 +/- 46.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 299      |\n",
      "|    mean_reward      | 299      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 196000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000695 |\n",
      "|    n_updates        | 48874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1710     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14497    |\n",
      "|    total_timesteps  | 196894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 49098    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=284.20 +/- 34.11\n",
      "Episode length: 284.20 +/- 34.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 284      |\n",
      "|    mean_reward      | 284      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 198000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 49374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14593    |\n",
      "|    total_timesteps  | 198122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 49405    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 128      |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1730     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14651    |\n",
      "|    total_timesteps  | 199222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 49680    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_200000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_200000_steps.pkl\n",
      "Saving model VecNormalize to ./checkpoints/model_vecnormalize_200000_steps.pkl\n",
      "Eval num_timesteps=200000, episode_reward=252.00 +/- 59.33\n",
      "Episode length: 252.00 +/- 59.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 252      |\n",
      "|    mean_reward      | 252      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000787 |\n",
      "|    n_updates        | 49874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14804    |\n",
      "|    total_timesteps  | 200575   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 50018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1750     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14872    |\n",
      "|    total_timesteps  | 201810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 50327    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=202000, episode_reward=242.80 +/- 53.36\n",
      "Episode length: 242.80 +/- 53.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 243      |\n",
      "|    mean_reward      | 243      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 202000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 50374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 14976    |\n",
      "|    total_timesteps  | 203138   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 50659    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=204000, episode_reward=169.60 +/- 2.24\n",
      "Episode length: 169.60 +/- 2.24\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 170      |\n",
      "|    mean_reward      | 170      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 204000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 50874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1770     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15081    |\n",
      "|    total_timesteps  | 204590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 51022    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15148    |\n",
      "|    total_timesteps  | 205866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 51341    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=206000, episode_reward=242.00 +/- 89.09\n",
      "Episode length: 242.00 +/- 89.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 242      |\n",
      "|    mean_reward      | 242      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 206000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 51374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1790     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15248    |\n",
      "|    total_timesteps  | 207154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 51663    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=262.20 +/- 29.08\n",
      "Episode length: 262.20 +/- 29.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 262      |\n",
      "|    mean_reward      | 262      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 208000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 51874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15342    |\n",
      "|    total_timesteps  | 208357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 51963    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1810     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15404    |\n",
      "|    total_timesteps  | 209542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00078  |\n",
      "|    n_updates        | 52260    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=205.00 +/- 21.54\n",
      "Episode length: 205.00 +/- 21.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 205      |\n",
      "|    mean_reward      | 205      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 210000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000536 |\n",
      "|    n_updates        | 52374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15499    |\n",
      "|    total_timesteps  | 210822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00203  |\n",
      "|    n_updates        | 52580    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=212000, episode_reward=389.20 +/- 183.27\n",
      "Episode length: 389.20 +/- 183.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 389      |\n",
      "|    mean_reward      | 389      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 212000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 52874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1830     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15619    |\n",
      "|    total_timesteps  | 212254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 52938    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 127      |\n",
      "|    ep_rew_mean      | 127      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15693    |\n",
      "|    total_timesteps  | 213650   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000936 |\n",
      "|    n_updates        | 53287    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=214000, episode_reward=225.20 +/- 47.37\n",
      "Episode length: 225.20 +/- 47.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 225      |\n",
      "|    mean_reward      | 225      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 214000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000532 |\n",
      "|    n_updates        | 53374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1850     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15790    |\n",
      "|    total_timesteps  | 214806   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 53576    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15853    |\n",
      "|    total_timesteps  | 215938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 53859    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=216000, episode_reward=282.60 +/- 86.54\n",
      "Episode length: 282.60 +/- 86.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 283      |\n",
      "|    mean_reward      | 283      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 216000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000705 |\n",
      "|    n_updates        | 53874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1870     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 15955    |\n",
      "|    total_timesteps  | 217167   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 54166    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=218000, episode_reward=264.80 +/- 15.01\n",
      "Episode length: 264.80 +/- 15.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 265      |\n",
      "|    mean_reward      | 265      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 218000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 54374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16042    |\n",
      "|    total_timesteps  | 218246   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000841 |\n",
      "|    n_updates        | 54436    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1890     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16119    |\n",
      "|    total_timesteps  | 219666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0008   |\n",
      "|    n_updates        | 54791    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=281.60 +/- 46.33\n",
      "Episode length: 281.60 +/- 46.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 282      |\n",
      "|    mean_reward      | 282      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 220000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 54874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16234    |\n",
      "|    total_timesteps  | 221218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000551 |\n",
      "|    n_updates        | 55179    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=222000, episode_reward=311.40 +/- 54.45\n",
      "Episode length: 311.40 +/- 54.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 311      |\n",
      "|    mean_reward      | 311      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 222000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000723 |\n",
      "|    n_updates        | 55374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1910     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16342    |\n",
      "|    total_timesteps  | 222651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 55537    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16406    |\n",
      "|    total_timesteps  | 223842   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 55835    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=224000, episode_reward=209.40 +/- 26.07\n",
      "Episode length: 209.40 +/- 26.07\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 209      |\n",
      "|    mean_reward      | 209      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 224000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000562 |\n",
      "|    n_updates        | 55874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1930     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16501    |\n",
      "|    total_timesteps  | 225113   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00234  |\n",
      "|    n_updates        | 56152    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=226000, episode_reward=287.60 +/- 55.20\n",
      "Episode length: 287.60 +/- 55.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 288      |\n",
      "|    mean_reward      | 288      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 226000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000443 |\n",
      "|    n_updates        | 56374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16609    |\n",
      "|    total_timesteps  | 226478   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 56494    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1950     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16677    |\n",
      "|    total_timesteps  | 227710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000675 |\n",
      "|    n_updates        | 56802    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=228000, episode_reward=319.00 +/- 65.60\n",
      "Episode length: 319.00 +/- 65.60\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 319      |\n",
      "|    mean_reward      | 319      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 228000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 56874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16779    |\n",
      "|    total_timesteps  | 228946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00093  |\n",
      "|    n_updates        | 57111    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=242.00 +/- 33.48\n",
      "Episode length: 242.00 +/- 33.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 242      |\n",
      "|    mean_reward      | 242      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 230000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 57374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1970     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16878    |\n",
      "|    total_timesteps  | 230258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 57439    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 16953    |\n",
      "|    total_timesteps  | 231686   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 57796    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=232000, episode_reward=346.40 +/- 78.96\n",
      "Episode length: 346.40 +/- 78.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 346      |\n",
      "|    mean_reward      | 346      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 232000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 57874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1990     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17059    |\n",
      "|    total_timesteps  | 233065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 58140    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=234000, episode_reward=181.20 +/- 12.58\n",
      "Episode length: 181.20 +/- 12.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 181      |\n",
      "|    mean_reward      | 181      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 234000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000696 |\n",
      "|    n_updates        | 58374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17154    |\n",
      "|    total_timesteps  | 234353   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 58462    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2010     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17224    |\n",
      "|    total_timesteps  | 235666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 58791    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=236000, episode_reward=310.60 +/- 58.25\n",
      "Episode length: 310.60 +/- 58.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 311      |\n",
      "|    mean_reward      | 311      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 236000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000385 |\n",
      "|    n_updates        | 58874    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 127      |\n",
      "|    ep_rew_mean      | 127      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17323    |\n",
      "|    total_timesteps  | 236962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 59115    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=238000, episode_reward=308.60 +/- 35.10\n",
      "Episode length: 308.60 +/- 35.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 309      |\n",
      "|    mean_reward      | 309      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 238000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0039   |\n",
      "|    n_updates        | 59374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2030     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17431    |\n",
      "|    total_timesteps  | 238424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000639 |\n",
      "|    n_updates        | 59480    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 128      |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17498    |\n",
      "|    total_timesteps  | 239702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000762 |\n",
      "|    n_updates        | 59800    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=301.40 +/- 53.52\n",
      "Episode length: 301.40 +/- 53.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 301      |\n",
      "|    mean_reward      | 301      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 240000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000679 |\n",
      "|    n_updates        | 59874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2050     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17606    |\n",
      "|    total_timesteps  | 241118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 60154    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=242000, episode_reward=356.00 +/- 112.62\n",
      "Episode length: 356.00 +/- 112.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 356      |\n",
      "|    mean_reward      | 356      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 242000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000976 |\n",
      "|    n_updates        | 60374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17730    |\n",
      "|    total_timesteps  | 242674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 60543    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=244000, episode_reward=435.60 +/- 169.61\n",
      "Episode length: 435.60 +/- 169.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 436      |\n",
      "|    mean_reward      | 436      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 244000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 60874    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | 134      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2070     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17854    |\n",
      "|    total_timesteps  | 244206   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00481  |\n",
      "|    n_updates        | 60926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 17920    |\n",
      "|    total_timesteps  | 245451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000542 |\n",
      "|    n_updates        | 61237    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=246000, episode_reward=217.60 +/- 32.68\n",
      "Episode length: 217.60 +/- 32.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 218      |\n",
      "|    mean_reward      | 218      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 246000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 61374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2090     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18026    |\n",
      "|    total_timesteps  | 246900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 61599    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=248000, episode_reward=284.60 +/- 53.84\n",
      "Episode length: 284.60 +/- 53.84\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 285      |\n",
      "|    mean_reward      | 285      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 248000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 61874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | 135      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18141    |\n",
      "|    total_timesteps  | 248426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000962 |\n",
      "|    n_updates        | 61981    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | 135      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2110     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18208    |\n",
      "|    total_timesteps  | 249706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000743 |\n",
      "|    n_updates        | 62301    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_250000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_250000_steps.pkl\n",
      "Saving model VecNormalize to ./checkpoints/model_vecnormalize_250000_steps.pkl\n",
      "Eval num_timesteps=250000, episode_reward=166.00 +/- 2.10\n",
      "Episode length: 166.00 +/- 2.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 166      |\n",
      "|    mean_reward      | 166      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000904 |\n",
      "|    n_updates        | 62374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 136      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18364    |\n",
      "|    total_timesteps  | 251202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000572 |\n",
      "|    n_updates        | 62675    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=252000, episode_reward=233.40 +/- 55.74\n",
      "Episode length: 233.40 +/- 55.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 233      |\n",
      "|    mean_reward      | 233      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 252000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 62874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 137      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2130     |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18478    |\n",
      "|    total_timesteps  | 252662   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000892 |\n",
      "|    n_updates        | 63040    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1de2c005d60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Começa o treinamento\n",
    "model._last_obs = None\n",
    "model.learn(total_timesteps=250000, callback=callback, log_interval=10, reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_4000\\3477431199.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Total Reward for episode 0 is [29.24366]\n",
      "Total Reward for episode 1 is [8.525146]\n",
      "Total Reward for episode 2 is [10.116716]\n",
      "Total Reward for episode 3 is [8.206295]\n",
      "Total Reward for episode 4 is [7.6212187]\n"
     ]
    }
   ],
   "source": [
    "env2 = get_env()\n",
    "model = get_model()\n",
    "model.load('checkpoints/model_200000_steps') \n",
    "\n",
    "for episode in range(5): \n",
    "    obs = env2.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env2.step(action)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b738c49bf83731c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b738c49bf83731c3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/DQN_0/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE A SECTION FOR RESUMING TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9105c753ba2e810590fbe03dc7a47b222fde04124da1bb9f952ac899bb56b210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
