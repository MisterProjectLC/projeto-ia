{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dependências do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in e:\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in e:\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in e:\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "#Instalando o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in e:\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: mouseinfo in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pymsgbox in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pyrect in e:\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in e:\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Caso não consiga pydirectinput\n",
    "%pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in e:\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in e:\\anaconda3\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.11 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.12.0)\n",
      "Requirement already satisfied: psutil in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: opencv-python in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: ale-py==0.7.4 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.3.1)\n",
      "Requirement already satisfied: importlib-resources in e:\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.5.4)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda3\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (63.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: libtorrent in e:\\anaconda3\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca de aprendizado por reforço\n",
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mss in e:\\anaconda3\\lib\\site-packages (7.0.1)\n",
      "Requirement already satisfied: pydirectinput in e:\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: pytesseract in e:\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para captura de tela\n",
    "from mss import mss\n",
    "#import pyautogui #para comandos de teclado\n",
    "import cv2 \n",
    "#Tratamentos dos frames\n",
    "import numpy as np \n",
    "import pyautogui\n",
    "#Framework intermediário paara trabalhar com as imagens\n",
    "#import pytesseract #para extrair o game over da imagem\n",
    "from matplotlib import pyplot as plt #Visualizando resultados\n",
    "import time\n",
    "from PIL import Image\n",
    "#Coisas para construir o ambinete\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete, Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import base64\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construindo o Ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe para definir o ambiente\n",
    "class WebGame(Env):\n",
    "    #ESSAS FUNÇÃO SÃO NECESSÁRIAS POR CONTA DO GYM\n",
    "    #Função responsavel pela inicialização do ambiente;\n",
    "    #Portanto onde ficam todas as variaveis do ambiente, configuração das ações e da observação \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Configuração do tempo\n",
    "        self.print_time = .005\n",
    "        self.wait_time = .015\n",
    "        \n",
    "        #Configuração do espaço\n",
    "        #self.observation_space = Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8)\n",
    "        self.observation_space = Dict({\n",
    "            \"print\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"print2\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"print3\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            #\"print4\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            \"score\":Box(low=0, high=10000, shape=(1,), dtype=np.uint8),\n",
    "                                      })\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "        #Variavei para a captura de tela\n",
    "        self.screen_cap = mss() #Lib de captura de tela\n",
    "        self.game_location = {\"top\": 300, \"left\": 0, \"width\": 650, \"height\": 500} #Área do monitor com \n",
    "        self.game_done = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 640}\n",
    "\n",
    "        self.chromedriver_path = \"./chromedriver.exe\"\n",
    "        _chrome_options = webdriver.ChromeOptions()\n",
    "        _chrome_options.add_argument(\"--mute-audio\")\n",
    "        _chrome_options.add_argument(\"--disable-gpu\")\n",
    "        self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n",
    "\n",
    "        self.first_image = np.zeros(5)\n",
    "        self.last_image = np.zeros((500,650,3))\n",
    "        \n",
    "        #Dicionário de ações\n",
    "        self.action_dict = {\n",
    "            0:Keys.ARROW_DOWN,\n",
    "            1:Keys.ARROW_UP,\n",
    "            2:'nothing'\n",
    "        }\n",
    "\n",
    "    #Função responsavel por passar as ações pro jogo, para fazer algo pro jogo\n",
    "    def step(self, action):\n",
    "        # Se ação escolhida for um dos botões, realizar a ação.\n",
    "        if action != 2:\n",
    "            self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(self.action_dict[int(action)])\n",
    "        \n",
    "        #Checa a próxima ação\n",
    "        observation = self.get_observation()\n",
    "        #Todas as ações tem que verificar se a ação acabou\n",
    "        done, done_cap = self.get_done() \n",
    "        \n",
    "        #Pegando o score do jogo\n",
    "        score = self.get_score()\n",
    "        #Ganhamos 1 ponto por cada frame que estamos vivos.\n",
    "        reward = 1\n",
    "        #É um dicionário de informações que retornam através do que a gente precisa\n",
    "        info = {\n",
    "            'score':score\n",
    "        }\n",
    "\n",
    "        time.sleep(self.wait_time)\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "        \n",
    "\n",
    "    #Função para a visualização do jogo:\n",
    "    def render(self, mode: str='human'):\n",
    "        img = cv2.cvtColor(self._get_image(), cv2.COLOR_BGR2RGB)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "        # cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     self.close()\n",
    "\n",
    "    #Função responsavel por recomeçar o jogo\n",
    "    def reset(self):\n",
    "        #Try catch precisa existir pq toda a vez q o selenium detecta que ele viu o chrome dino,\n",
    "        #ele dispara um erro que esta sem internet.\n",
    "        try:\n",
    "            self._driver.get('chrome://dino')\n",
    "            \n",
    "        except WebDriverException:\n",
    "            pass\n",
    "        WebDriverWait(self._driver, 10).until(\n",
    "            EC.presence_of_element_located((\n",
    "                By.CLASS_NAME, \n",
    "                \"runner-canvas\"\n",
    "            ))\n",
    "        )\n",
    "        self._driver.implicitly_wait(0.5)\n",
    "        self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "        return self.get_observation()\n",
    "\n",
    "    #FUNÇÕES CUSTOM\n",
    "    #Fecha a parte de visualização\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        #shape = np.zeros(1)\n",
    "        #shape[0] = int(score)\n",
    "        return int(score)\n",
    "    \n",
    "    def get_score_shape(self):\n",
    "        shape = np.zeros(1)\n",
    "        shape[0] = int(self.get_score())\n",
    "        return shape\n",
    "    \n",
    "    def get_img(self):\n",
    "        LEADING_TEXT = \"data:image/png;base64,\"\n",
    "        canvas = self._driver.execute_script(\"return document.querySelector('canvas.runner-canvas').toDataURL()\")\n",
    "        img = canvas[len(LEADING_TEXT):]\n",
    "        img_data = np.array(Image.open(BytesIO(base64.b64decode(img))))\n",
    "        return img_data \n",
    "        # img = self._driver.execute_script()\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_print(self): \n",
    "\n",
    "        #img = numpy.array(self.screen_cap.grab(game_location))[:,:,3].astype(np.uint8)\n",
    "        raw = np.array(self.get_img())[:,:,:3].astype(np.uint8)\n",
    "        img = raw[:200,:400]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (200,83))\n",
    "        channel = np.reshape(resized, (1,83,200))\n",
    "        \n",
    "        self.first_image = self.last_image\n",
    "        self.last_image = raw\n",
    "        \n",
    "        return channel\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_observation(self): \n",
    "        print1 = self.get_print()\n",
    "        self._driver.implicitly_wait(self.print_time)\n",
    "        print2 = self.get_print()\n",
    "        self._driver.implicitly_wait(self.print_time)\n",
    "        return {\"print\":print1, \"print2\":print2, \"print3\":self.get_print(), \"score\":self.get_score_shape() }\n",
    "        #return self.get_print()\n",
    "\n",
    "\n",
    "    #Função para pegar o texto de fim de jogo:\n",
    "    def get_done(self):\n",
    "        #Se as duas imagens iniciais forem iguais acabou jogo\n",
    "        done = False\n",
    "        #Colando a primeira condição devido ao fator de que as formas diferentes estavam dando problema na comparação devido ao np.all\n",
    "        \n",
    "        if self.first_image.shape != self.last_image.shape:\n",
    "            return done, self.last_image\n",
    "\n",
    "        if np.all(np.equal(self.first_image, self.last_image)) and not self._driver.execute_script(\"return Runner.instance_.playing\"):\n",
    "            done = True\n",
    "        \n",
    "        return done, self.last_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback, CallbackList\n",
    "# Verificando se o ambiente é válido para fazer as coisa\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack,SubprocVecEnv\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.logger import Figure, configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_16736\\1759824243.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#env_lambda = lambda: WebGame()\n",
    "#env2 = SubprocVecEnv([env_lambda for i in range(4)])\n",
    "env2 = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'print': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " 'print2': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " 'print3': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " 'score': array([0.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criandos as pastas para que funcione.\n",
    "CHECKPOINT_DIR = './checkpoints/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=500,\n",
    "  save_path=CHECKPOINT_DIR,\n",
    "  name_prefix=\"model\",\n",
    "  save_replay_buffer=False,\n",
    "  save_vecnormalize=True,\n",
    "    verbose=2\n",
    ")\n",
    "eval_callback = EvalCallback(env2, best_model_save_path=CHECKPOINT_DIR,\n",
    "                             log_path=LOG_DIR, eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "callback = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = PPO('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, learning_rate=0.005, verbose=2, policy_kwargs=dict(normalize_images=False))\n",
    "    model = DQN('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, verbose=2, buffer_size=12000, \n",
    "        learning_starts=500, exploration_fraction=0.4, exploration_initial_eps=0.9, exploration_final_eps=0.05,\n",
    "                policy_kwargs=dict(normalize_images=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/DQN_25\n",
      "Saving model checkpoint to ./checkpoints/model_500_steps.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:272: UserWarning: Path 'checkpoints\\model_replay_buffer_500_steps.pkl' exists, will overwrite it.\n",
      "  warnings.warn(f\"Path '{path}' exists, will overwrite it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_500_steps.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500, episode_reward=109.20 +/- 3.87\n",
      "Episode length: 109.20 +/- 3.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 109      |\n",
      "|    mean_reward      | 109      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 500      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.1     |\n",
      "|    ep_rew_mean      | 91.1     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 729      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 57       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.4     |\n",
      "|    ep_rew_mean      | 82.4     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 989      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000622 |\n",
      "|    n_updates        | 122      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_1000_steps.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:272: UserWarning: Path 'checkpoints\\model_replay_buffer_1000_steps.pkl' exists, will overwrite it.\n",
      "  warnings.warn(f\"Path '{path}' exists, will overwrite it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_1000_steps.pkl\n",
      "Eval num_timesteps=1000, episode_reward=84.80 +/- 1.47\n",
      "Episode length: 84.80 +/- 1.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 84.8     |\n",
      "|    mean_reward      | 84.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.8     |\n",
      "|    ep_rew_mean      | 79.8     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 1276     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 193      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_1500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_1500_steps.pkl\n",
      "Eval num_timesteps=1500, episode_reward=78.80 +/- 1.33\n",
      "Episode length: 78.80 +/- 1.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 78.8     |\n",
      "|    mean_reward      | 78.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.4     |\n",
      "|    ep_rew_mean      | 79.4     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 1588     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 271      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.1     |\n",
      "|    ep_rew_mean      | 74.1     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 1778     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00127  |\n",
      "|    n_updates        | 319      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 71       |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 1989     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 372      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_2000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_2000_steps.pkl\n",
      "Eval num_timesteps=2000, episode_reward=92.00 +/- 2.37\n",
      "Episode length: 92.00 +/- 2.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92       |\n",
      "|    mean_reward      | 92       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000995 |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 70.3     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 2249     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 437      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_2500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_2500_steps.pkl\n",
      "Eval num_timesteps=2500, episode_reward=90.60 +/- 3.38\n",
      "Episode length: 90.60 +/- 3.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 90.6     |\n",
      "|    mean_reward      | 90.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | 71.2     |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 416      |\n",
      "|    total_timesteps  | 2565     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000459 |\n",
      "|    n_updates        | 516      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70       |\n",
      "|    ep_rew_mean      | 70       |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 439      |\n",
      "|    total_timesteps  | 2801     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000553 |\n",
      "|    n_updates        | 575      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_3000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_3000_steps.pkl\n",
      "Eval num_timesteps=3000, episode_reward=92.40 +/- 8.11\n",
      "Episode length: 92.40 +/- 8.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.4     |\n",
      "|    mean_reward      | 92.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 70.7     |\n",
      "|    exploration_rate | 0.753    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 507      |\n",
      "|    total_timesteps  | 3109     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 652      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 69.9     |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 531      |\n",
      "|    total_timesteps  | 3354     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000372 |\n",
      "|    n_updates        | 713      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_3500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_3500_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3500, episode_reward=95.60 +/- 11.91\n",
      "Episode length: 95.60 +/- 11.91\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 95.6     |\n",
      "|    mean_reward      | 95.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.4     |\n",
      "|    ep_rew_mean      | 69.4     |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 596      |\n",
      "|    total_timesteps  | 3609     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 777      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 68.6     |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 619      |\n",
      "|    total_timesteps  | 3841     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000609 |\n",
      "|    n_updates        | 835      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_4000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_4000_steps.pkl\n",
      "Eval num_timesteps=4000, episode_reward=114.60 +/- 14.35\n",
      "Episode length: 114.60 +/- 14.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 115      |\n",
      "|    mean_reward      | 115      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 68.5     |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 691      |\n",
      "|    total_timesteps  | 4109     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000701 |\n",
      "|    n_updates        | 902      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.9     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 714      |\n",
      "|    total_timesteps  | 4345     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000354 |\n",
      "|    n_updates        | 961      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_4500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_4500_steps.pkl\n",
      "Eval num_timesteps=4500, episode_reward=86.00 +/- 2.61\n",
      "Episode length: 86.00 +/- 2.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 86       |\n",
      "|    mean_reward      | 86       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 777      |\n",
      "|    total_timesteps  | 4622     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000727 |\n",
      "|    n_updates        | 1030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 799      |\n",
      "|    total_timesteps  | 4849     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000566 |\n",
      "|    n_updates        | 1087     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_5000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_5000_steps.pkl\n",
      "Eval num_timesteps=5000, episode_reward=101.40 +/- 9.09\n",
      "Episode length: 101.40 +/- 9.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 101      |\n",
      "|    mean_reward      | 101      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000699 |\n",
      "|    n_updates        | 1124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 864      |\n",
      "|    total_timesteps  | 5110     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00057  |\n",
      "|    n_updates        | 1152     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 885      |\n",
      "|    total_timesteps  | 5325     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000804 |\n",
      "|    n_updates        | 1206     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_5500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_5500_steps.pkl\n",
      "Eval num_timesteps=5500, episode_reward=78.60 +/- 3.50\n",
      "Episode length: 78.60 +/- 3.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 78.6     |\n",
      "|    mean_reward      | 78.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000675 |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 944      |\n",
      "|    total_timesteps  | 5549     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000619 |\n",
      "|    n_updates        | 1262     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 972      |\n",
      "|    total_timesteps  | 5797     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000503 |\n",
      "|    n_updates        | 1324     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_6000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_6000_steps.pkl\n",
      "Eval num_timesteps=6000, episode_reward=115.20 +/- 36.53\n",
      "Episode length: 115.20 +/- 36.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 115      |\n",
      "|    mean_reward      | 115      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1045     |\n",
      "|    total_timesteps  | 6053     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 1388     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1067     |\n",
      "|    total_timesteps  | 6281     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000743 |\n",
      "|    n_updates        | 1445     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_6500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_6500_steps.pkl\n",
      "Eval num_timesteps=6500, episode_reward=102.40 +/- 3.61\n",
      "Episode length: 102.40 +/- 3.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 102      |\n",
      "|    mean_reward      | 102      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000471 |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1133     |\n",
      "|    total_timesteps  | 6569     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 1517     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.579    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1155     |\n",
      "|    total_timesteps  | 6793     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000398 |\n",
      "|    n_updates        | 1573     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_7000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_7000_steps.pkl\n",
      "Eval num_timesteps=7000, episode_reward=92.20 +/- 3.12\n",
      "Episode length: 92.20 +/- 3.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.2     |\n",
      "|    mean_reward      | 92.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000885 |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1218     |\n",
      "|    total_timesteps  | 7053     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 1638     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1243     |\n",
      "|    total_timesteps  | 7313     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 1703     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_7500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_7500_steps.pkl\n",
      "Eval num_timesteps=7500, episode_reward=109.00 +/- 12.18\n",
      "Episode length: 109.00 +/- 12.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 109      |\n",
      "|    mean_reward      | 109      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000714 |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1311     |\n",
      "|    total_timesteps  | 7556     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000802 |\n",
      "|    n_updates        | 1763     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1332     |\n",
      "|    total_timesteps  | 7769     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000662 |\n",
      "|    n_updates        | 1817     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1355     |\n",
      "|    total_timesteps  | 7997     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000534 |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_8000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_8000_steps.pkl\n",
      "Eval num_timesteps=8000, episode_reward=83.60 +/- 2.42\n",
      "Episode length: 83.60 +/- 2.42\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 83.6     |\n",
      "|    mean_reward      | 83.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1413     |\n",
      "|    total_timesteps  | 8209     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00073  |\n",
      "|    n_updates        | 1927     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1435     |\n",
      "|    total_timesteps  | 8429     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000928 |\n",
      "|    n_updates        | 1982     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_8500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_8500_steps.pkl\n",
      "Eval num_timesteps=8500, episode_reward=110.60 +/- 32.36\n",
      "Episode length: 110.60 +/- 32.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 111      |\n",
      "|    mean_reward      | 111      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 1999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1503     |\n",
      "|    total_timesteps  | 8681     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 2045     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1525     |\n",
      "|    total_timesteps  | 8899     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000703 |\n",
      "|    n_updates        | 2099     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_9000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_9000_steps.pkl\n",
      "Eval num_timesteps=9000, episode_reward=88.80 +/- 3.06\n",
      "Episode length: 88.80 +/- 3.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 88.8     |\n",
      "|    mean_reward      | 88.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000911 |\n",
      "|    n_updates        | 2124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1589     |\n",
      "|    total_timesteps  | 9169     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000666 |\n",
      "|    n_updates        | 2167     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1610     |\n",
      "|    total_timesteps  | 9381     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000525 |\n",
      "|    n_updates        | 2220     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_9500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_9500_steps.pkl\n",
      "Eval num_timesteps=9500, episode_reward=92.40 +/- 3.88\n",
      "Episode length: 92.40 +/- 3.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.4     |\n",
      "|    mean_reward      | 92.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000486 |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1670     |\n",
      "|    total_timesteps  | 9605     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 2276     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1692     |\n",
      "|    total_timesteps  | 9836     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000507 |\n",
      "|    n_updates        | 2333     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_10000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_10000_steps.pkl\n",
      "Eval num_timesteps=10000, episode_reward=94.00 +/- 2.83\n",
      "Episode length: 94.00 +/- 2.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 94       |\n",
      "|    mean_reward      | 94       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000464 |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1755     |\n",
      "|    total_timesteps  | 10100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 2399     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1781     |\n",
      "|    total_timesteps  | 10359    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 2464     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_10500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_10500_steps.pkl\n",
      "Eval num_timesteps=10500, episode_reward=84.80 +/- 8.16\n",
      "Episode length: 84.80 +/- 8.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 84.8     |\n",
      "|    mean_reward      | 84.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1844     |\n",
      "|    total_timesteps  | 10620    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 2529     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1867     |\n",
      "|    total_timesteps  | 10845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 2586     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_11000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_11000_steps.pkl\n",
      "Eval num_timesteps=11000, episode_reward=101.80 +/- 10.50\n",
      "Episode length: 101.80 +/- 10.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 102      |\n",
      "|    mean_reward      | 102      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 2624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1940     |\n",
      "|    total_timesteps  | 11177    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 2669     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 1961     |\n",
      "|    total_timesteps  | 11385    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 2721     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_11500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_11500_steps.pkl\n",
      "Eval num_timesteps=11500, episode_reward=91.00 +/- 1.10\n",
      "Episode length: 91.00 +/- 1.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 91       |\n",
      "|    mean_reward      | 91       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 2749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2028     |\n",
      "|    total_timesteps  | 11694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 2798     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2052     |\n",
      "|    total_timesteps  | 11937    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 2859     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_12000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_12000_steps.pkl\n",
      "Eval num_timesteps=12000, episode_reward=80.00 +/- 1.67\n",
      "Episode length: 80.00 +/- 1.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 80       |\n",
      "|    mean_reward      | 80       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2113     |\n",
      "|    total_timesteps  | 12172    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 2917     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2138     |\n",
      "|    total_timesteps  | 12425    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00986  |\n",
      "|    n_updates        | 2981     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_12500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_12500_steps.pkl\n",
      "Eval num_timesteps=12500, episode_reward=104.80 +/- 17.92\n",
      "Episode length: 104.80 +/- 17.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2204     |\n",
      "|    total_timesteps  | 12685    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 3046     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2226     |\n",
      "|    total_timesteps  | 12905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 3101     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_13000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_13000_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=13000, episode_reward=118.20 +/- 18.08\n",
      "Episode length: 118.20 +/- 18.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 118      |\n",
      "|    mean_reward      | 118      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 3124     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2301     |\n",
      "|    total_timesteps  | 13210    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 3177     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2325     |\n",
      "|    total_timesteps  | 13449    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00336  |\n",
      "|    n_updates        | 3237     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_13500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_13500_steps.pkl\n",
      "Eval num_timesteps=13500, episode_reward=112.40 +/- 22.39\n",
      "Episode length: 112.40 +/- 22.39\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 112      |\n",
      "|    mean_reward      | 112      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2410     |\n",
      "|    total_timesteps  | 13832    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 3332     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_14000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_14000_steps.pkl\n",
      "Eval num_timesteps=14000, episode_reward=92.40 +/- 6.50\n",
      "Episode length: 92.40 +/- 6.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.4     |\n",
      "|    mean_reward      | 92.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2472     |\n",
      "|    total_timesteps  | 14053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 3388     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2495     |\n",
      "|    total_timesteps  | 14273    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 3443     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_14500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_14500_steps.pkl\n",
      "Eval num_timesteps=14500, episode_reward=109.80 +/- 19.79\n",
      "Episode length: 109.80 +/- 19.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 110      |\n",
      "|    mean_reward      | 110      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00247  |\n",
      "|    n_updates        | 3499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2567     |\n",
      "|    total_timesteps  | 14553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 3513     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2592     |\n",
      "|    total_timesteps  | 14796    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000892 |\n",
      "|    n_updates        | 3573     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_15000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_15000_steps.pkl\n",
      "Eval num_timesteps=15000, episode_reward=90.60 +/- 8.40\n",
      "Episode length: 90.60 +/- 8.40\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 90.6     |\n",
      "|    mean_reward      | 90.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 3624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.189    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2658     |\n",
      "|    total_timesteps  | 15061    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 3640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2680     |\n",
      "|    total_timesteps  | 15277    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 3694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2701     |\n",
      "|    total_timesteps  | 15485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 3746     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_15500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_15500_steps.pkl\n",
      "Eval num_timesteps=15500, episode_reward=89.60 +/- 2.33\n",
      "Episode length: 89.60 +/- 2.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 89.6     |\n",
      "|    mean_reward      | 89.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 3749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2763     |\n",
      "|    total_timesteps  | 15729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 3807     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2785     |\n",
      "|    total_timesteps  | 15937    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00181  |\n",
      "|    n_updates        | 3859     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_16000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_16000_steps.pkl\n",
      "Eval num_timesteps=16000, episode_reward=100.80 +/- 10.51\n",
      "Episode length: 100.80 +/- 10.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 101      |\n",
      "|    mean_reward      | 101      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000833 |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2854     |\n",
      "|    total_timesteps  | 16213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000592 |\n",
      "|    n_updates        | 3928     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2877     |\n",
      "|    total_timesteps  | 16429    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00201  |\n",
      "|    n_updates        | 3982     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_16500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_16500_steps.pkl\n",
      "Eval num_timesteps=16500, episode_reward=86.80 +/- 7.25\n",
      "Episode length: 86.80 +/- 7.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 86.8     |\n",
      "|    mean_reward      | 86.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 3999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2939     |\n",
      "|    total_timesteps  | 16663    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 4040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 2960     |\n",
      "|    total_timesteps  | 16865    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 4091     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_17000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_17000_steps.pkl\n",
      "Eval num_timesteps=17000, episode_reward=100.20 +/- 1.47\n",
      "Episode length: 100.20 +/- 1.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 100      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0973   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00999  |\n",
      "|    n_updates        | 4124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.0921   |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3022     |\n",
      "|    total_timesteps  | 17109    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 4152     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.0809   |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3046     |\n",
      "|    total_timesteps  | 17345    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000917 |\n",
      "|    n_updates        | 4211     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_17500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_17500_steps.pkl\n",
      "Eval num_timesteps=17500, episode_reward=73.20 +/- 9.62\n",
      "Episode length: 73.20 +/- 9.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 73.2     |\n",
      "|    mean_reward      | 73.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0737   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 4249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.0702   |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3113     |\n",
      "|    total_timesteps  | 17573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 4268     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.0628   |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3135     |\n",
      "|    total_timesteps  | 17729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 4307     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.0556   |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3157     |\n",
      "|    total_timesteps  | 17881    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 4345     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_18000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_18000_steps.pkl\n",
      "Eval num_timesteps=18000, episode_reward=83.40 +/- 6.09\n",
      "Episode length: 83.40 +/- 6.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 83.4     |\n",
      "|    mean_reward      | 83.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3217     |\n",
      "|    total_timesteps  | 18049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 4387     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3241     |\n",
      "|    total_timesteps  | 18283    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000902 |\n",
      "|    n_updates        | 4445     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_18500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_18500_steps.pkl\n",
      "Eval num_timesteps=18500, episode_reward=91.80 +/- 4.96\n",
      "Episode length: 91.80 +/- 4.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 91.8     |\n",
      "|    mean_reward      | 91.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 4499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3308     |\n",
      "|    total_timesteps  | 18551    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 4512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3330     |\n",
      "|    total_timesteps  | 18759    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 4564     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3353     |\n",
      "|    total_timesteps  | 18985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 4621     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_19000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_19000_steps.pkl\n",
      "Eval num_timesteps=19000, episode_reward=129.80 +/- 39.61\n",
      "Episode length: 129.80 +/- 39.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 4624     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3419     |\n",
      "|    total_timesteps  | 19205    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00108  |\n",
      "|    n_updates        | 4676     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3442     |\n",
      "|    total_timesteps  | 19425    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 4731     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_19500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_19500_steps.pkl\n",
      "Eval num_timesteps=19500, episode_reward=105.40 +/- 19.87\n",
      "Episode length: 105.40 +/- 19.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 4749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3512     |\n",
      "|    total_timesteps  | 19689    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 4797     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3537     |\n",
      "|    total_timesteps  | 19934    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 4858     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_20000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_20000_steps.pkl\n",
      "Eval num_timesteps=20000, episode_reward=83.60 +/- 7.23\n",
      "Episode length: 83.60 +/- 7.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 83.6     |\n",
      "|    mean_reward      | 83.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3596     |\n",
      "|    total_timesteps  | 20160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 4914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3619     |\n",
      "|    total_timesteps  | 20373    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 4968     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_20500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_20500_steps.pkl\n",
      "Eval num_timesteps=20500, episode_reward=125.60 +/- 20.18\n",
      "Episode length: 125.60 +/- 20.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 126      |\n",
      "|    mean_reward      | 126      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0303   |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3687     |\n",
      "|    total_timesteps  | 20620    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 5029     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3711     |\n",
      "|    total_timesteps  | 20852    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 5087     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_21000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_21000_steps.pkl\n",
      "Eval num_timesteps=21000, episode_reward=90.00 +/- 11.88\n",
      "Episode length: 90.00 +/- 11.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 90       |\n",
      "|    mean_reward      | 90       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 5124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3778     |\n",
      "|    total_timesteps  | 21105    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 5151     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3800     |\n",
      "|    total_timesteps  | 21329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00568  |\n",
      "|    n_updates        | 5207     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_21500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_21500_steps.pkl\n",
      "Eval num_timesteps=21500, episode_reward=88.60 +/- 5.82\n",
      "Episode length: 88.60 +/- 5.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 88.6     |\n",
      "|    mean_reward      | 88.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 5249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3862     |\n",
      "|    total_timesteps  | 21553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 5263     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3883     |\n",
      "|    total_timesteps  | 21756    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 5313     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3908     |\n",
      "|    total_timesteps  | 21997    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_22000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_22000_steps.pkl\n",
      "Eval num_timesteps=22000, episode_reward=83.20 +/- 2.71\n",
      "Episode length: 83.20 +/- 2.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 83.2     |\n",
      "|    mean_reward      | 83.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3966     |\n",
      "|    total_timesteps  | 22202    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 5425     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 3987     |\n",
      "|    total_timesteps  | 22409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 5477     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_22500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_22500_steps.pkl\n",
      "Eval num_timesteps=22500, episode_reward=85.80 +/- 1.94\n",
      "Episode length: 85.80 +/- 1.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 85.8     |\n",
      "|    mean_reward      | 85.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 5499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4050     |\n",
      "|    total_timesteps  | 22649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00649  |\n",
      "|    n_updates        | 5537     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4072     |\n",
      "|    total_timesteps  | 22858    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00299  |\n",
      "|    n_updates        | 5589     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_23000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_23000_steps.pkl\n",
      "Eval num_timesteps=23000, episode_reward=90.40 +/- 8.33\n",
      "Episode length: 90.40 +/- 8.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 90.4     |\n",
      "|    mean_reward      | 90.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 5624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4137     |\n",
      "|    total_timesteps  | 23105    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 5651     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4165     |\n",
      "|    total_timesteps  | 23376    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 5718     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_23500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_23500_steps.pkl\n",
      "Eval num_timesteps=23500, episode_reward=82.40 +/- 1.50\n",
      "Episode length: 82.40 +/- 1.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 82.4     |\n",
      "|    mean_reward      | 82.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00681  |\n",
      "|    n_updates        | 5749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4226     |\n",
      "|    total_timesteps  | 23605    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00407  |\n",
      "|    n_updates        | 5776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4249     |\n",
      "|    total_timesteps  | 23828    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00447  |\n",
      "|    n_updates        | 5831     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_24000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_24000_steps.pkl\n",
      "Eval num_timesteps=24000, episode_reward=105.60 +/- 23.31\n",
      "Episode length: 105.60 +/- 23.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 106      |\n",
      "|    mean_reward      | 106      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0376   |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4312     |\n",
      "|    total_timesteps  | 24053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 5888     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4339     |\n",
      "|    total_timesteps  | 24311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 5952     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_24500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_24500_steps.pkl\n",
      "Eval num_timesteps=24500, episode_reward=92.00 +/- 9.82\n",
      "Episode length: 92.00 +/- 9.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92       |\n",
      "|    mean_reward      | 92       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 5999     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4405     |\n",
      "|    total_timesteps  | 24553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 6013     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4431     |\n",
      "|    total_timesteps  | 24805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 6076     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_25000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_25000_steps.pkl\n",
      "Eval num_timesteps=25000, episode_reward=85.60 +/- 1.36\n",
      "Episode length: 85.60 +/- 1.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 85.6     |\n",
      "|    mean_reward      | 85.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 6124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4493     |\n",
      "|    total_timesteps  | 25052    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 6137     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4521     |\n",
      "|    total_timesteps  | 25320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 6204     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_25500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_25500_steps.pkl\n",
      "Eval num_timesteps=25500, episode_reward=130.20 +/- 46.04\n",
      "Episode length: 130.20 +/- 46.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 6249     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4595     |\n",
      "|    total_timesteps  | 25553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00622  |\n",
      "|    n_updates        | 6263     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4623     |\n",
      "|    total_timesteps  | 25833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00549  |\n",
      "|    n_updates        | 6333     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_26000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_26000_steps.pkl\n",
      "Eval num_timesteps=26000, episode_reward=89.00 +/- 10.02\n",
      "Episode length: 89.00 +/- 10.02\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 89       |\n",
      "|    mean_reward      | 89       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00816  |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4694     |\n",
      "|    total_timesteps  | 26131    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 6407     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4717     |\n",
      "|    total_timesteps  | 26349    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 6462     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_26500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_26500_steps.pkl\n",
      "Eval num_timesteps=26500, episode_reward=94.00 +/- 7.69\n",
      "Episode length: 94.00 +/- 7.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 94       |\n",
      "|    mean_reward      | 94       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 6499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4783     |\n",
      "|    total_timesteps  | 26606    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 6526     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4806     |\n",
      "|    total_timesteps  | 26828    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00638  |\n",
      "|    n_updates        | 6581     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_27000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_27000_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=27000, episode_reward=120.40 +/- 29.65\n",
      "Episode length: 120.40 +/- 29.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 120      |\n",
      "|    mean_reward      | 120      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0046   |\n",
      "|    n_updates        | 6624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4880     |\n",
      "|    total_timesteps  | 27104    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 6650     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4902     |\n",
      "|    total_timesteps  | 27321    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 6705     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_27500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_27500_steps.pkl\n",
      "Eval num_timesteps=27500, episode_reward=79.00 +/- 2.68\n",
      "Episode length: 79.00 +/- 2.68\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 79       |\n",
      "|    mean_reward      | 79       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 6749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4964     |\n",
      "|    total_timesteps  | 27548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 6761     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 4990     |\n",
      "|    total_timesteps  | 27765    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 6816     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5016     |\n",
      "|    total_timesteps  | 27990    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 6872     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_28000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_28000_steps.pkl\n",
      "Eval num_timesteps=28000, episode_reward=101.60 +/- 23.58\n",
      "Episode length: 101.60 +/- 23.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 102      |\n",
      "|    mean_reward      | 102      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5083     |\n",
      "|    total_timesteps  | 28229    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 6932     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5105     |\n",
      "|    total_timesteps  | 28437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 6984     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_28500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_28500_steps.pkl\n",
      "Eval num_timesteps=28500, episode_reward=90.20 +/- 9.20\n",
      "Episode length: 90.20 +/- 9.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 90.2     |\n",
      "|    mean_reward      | 90.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 6999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5170     |\n",
      "|    total_timesteps  | 28693    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00309  |\n",
      "|    n_updates        | 7048     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5194     |\n",
      "|    total_timesteps  | 28927    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 7106     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_29000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_29000_steps.pkl\n",
      "Eval num_timesteps=29000, episode_reward=104.00 +/- 22.54\n",
      "Episode length: 104.00 +/- 22.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 104      |\n",
      "|    mean_reward      | 104      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 7124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5258     |\n",
      "|    total_timesteps  | 29157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 7164     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5283     |\n",
      "|    total_timesteps  | 29402    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 7225     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_29500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_29500_steps.pkl\n",
      "Eval num_timesteps=29500, episode_reward=113.40 +/- 24.78\n",
      "Episode length: 113.40 +/- 24.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 113      |\n",
      "|    mean_reward      | 113      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 7249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5359     |\n",
      "|    total_timesteps  | 29682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 7295     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5383     |\n",
      "|    total_timesteps  | 29893    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 7348     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_30000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_30000_steps.pkl\n",
      "Eval num_timesteps=30000, episode_reward=106.40 +/- 39.35\n",
      "Episode length: 106.40 +/- 39.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 106      |\n",
      "|    mean_reward      | 106      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5451     |\n",
      "|    total_timesteps  | 30101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 7400     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5472     |\n",
      "|    total_timesteps  | 30309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 7452     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_30500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_30500_steps.pkl\n",
      "Eval num_timesteps=30500, episode_reward=93.20 +/- 2.48\n",
      "Episode length: 93.20 +/- 2.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 93.2     |\n",
      "|    mean_reward      | 93.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5552     |\n",
      "|    total_timesteps  | 30709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 7552     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5581     |\n",
      "|    total_timesteps  | 30980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 7619     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_31000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_31000_steps.pkl\n",
      "Eval num_timesteps=31000, episode_reward=88.20 +/- 14.92\n",
      "Episode length: 88.20 +/- 14.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 88.2     |\n",
      "|    mean_reward      | 88.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 7624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5644     |\n",
      "|    total_timesteps  | 31221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 7680     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5667     |\n",
      "|    total_timesteps  | 31442    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 7735     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_31500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_31500_steps.pkl\n",
      "Eval num_timesteps=31500, episode_reward=89.40 +/- 18.70\n",
      "Episode length: 89.40 +/- 18.70\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 89.4     |\n",
      "|    mean_reward      | 89.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00725  |\n",
      "|    n_updates        | 7749     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5743     |\n",
      "|    total_timesteps  | 31692    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 7797     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5767     |\n",
      "|    total_timesteps  | 31865    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 7841     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_32000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_32000_steps.pkl\n",
      "Eval num_timesteps=32000, episode_reward=110.40 +/- 14.81\n",
      "Episode length: 110.40 +/- 14.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 110      |\n",
      "|    mean_reward      | 110      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5835     |\n",
      "|    total_timesteps  | 32101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 7900     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5866     |\n",
      "|    total_timesteps  | 32403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00433  |\n",
      "|    n_updates        | 7975     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_32500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_32500_steps.pkl\n",
      "Eval num_timesteps=32500, episode_reward=103.80 +/- 27.43\n",
      "Episode length: 103.80 +/- 27.43\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 104      |\n",
      "|    mean_reward      | 104      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 7999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5933     |\n",
      "|    total_timesteps  | 32653    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 8038     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 5960     |\n",
      "|    total_timesteps  | 32921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00967  |\n",
      "|    n_updates        | 8105     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_33000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_33000_steps.pkl\n",
      "Eval num_timesteps=33000, episode_reward=122.00 +/- 27.06\n",
      "Episode length: 122.00 +/- 27.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 122      |\n",
      "|    mean_reward      | 122      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00337  |\n",
      "|    n_updates        | 8124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6032     |\n",
      "|    total_timesteps  | 33173    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0537   |\n",
      "|    n_updates        | 8168     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6058     |\n",
      "|    total_timesteps  | 33421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00732  |\n",
      "|    n_updates        | 8230     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_33500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_33500_steps.pkl\n",
      "Eval num_timesteps=33500, episode_reward=118.00 +/- 15.01\n",
      "Episode length: 118.00 +/- 15.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 118      |\n",
      "|    mean_reward      | 118      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 8249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6133     |\n",
      "|    total_timesteps  | 33693    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 8298     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6161     |\n",
      "|    total_timesteps  | 33966    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 8366     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_34000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_34000_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=34000, episode_reward=91.20 +/- 18.63\n",
      "Episode length: 91.20 +/- 18.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 91.2     |\n",
      "|    mean_reward      | 91.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00575  |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6238     |\n",
      "|    total_timesteps  | 34201    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0778   |\n",
      "|    n_updates        | 8425     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6263     |\n",
      "|    total_timesteps  | 34391    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 8472     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_34500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_34500_steps.pkl\n",
      "Eval num_timesteps=34500, episode_reward=102.40 +/- 28.58\n",
      "Episode length: 102.40 +/- 28.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 102      |\n",
      "|    mean_reward      | 102      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6350     |\n",
      "|    total_timesteps  | 34669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 8542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6376     |\n",
      "|    total_timesteps  | 34879    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 8594     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_35000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_35000_steps.pkl\n",
      "Eval num_timesteps=35000, episode_reward=86.80 +/- 6.85\n",
      "Episode length: 86.80 +/- 6.85\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 86.8     |\n",
      "|    mean_reward      | 86.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 8624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6448     |\n",
      "|    total_timesteps  | 35121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 8655     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6470     |\n",
      "|    total_timesteps  | 35309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 8702     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_35500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_35500_steps.pkl\n",
      "Eval num_timesteps=35500, episode_reward=108.80 +/- 12.12\n",
      "Episode length: 108.80 +/- 12.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 109      |\n",
      "|    mean_reward      | 109      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 8749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6542     |\n",
      "|    total_timesteps  | 35557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 8764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6569     |\n",
      "|    total_timesteps  | 35817    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 8829     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_36000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_36000_steps.pkl\n",
      "Eval num_timesteps=36000, episode_reward=116.00 +/- 34.03\n",
      "Episode length: 116.00 +/- 34.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 116      |\n",
      "|    mean_reward      | 116      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6645     |\n",
      "|    total_timesteps  | 36094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0847   |\n",
      "|    n_updates        | 8898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6668     |\n",
      "|    total_timesteps  | 36309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 8952     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/model_36500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_36500_steps.pkl\n",
      "Eval num_timesteps=36500, episode_reward=92.80 +/- 15.83\n",
      "Episode length: 92.80 +/- 15.83\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.8     |\n",
      "|    mean_reward      | 92.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0812   |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6738     |\n",
      "|    total_timesteps  | 36580    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 9019     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6772     |\n",
      "|    total_timesteps  | 36909    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0583   |\n",
      "|    n_updates        | 9102     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_37000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_37000_steps.pkl\n",
      "Eval num_timesteps=37000, episode_reward=105.20 +/- 23.54\n",
      "Episode length: 105.20 +/- 23.54\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00627  |\n",
      "|    n_updates        | 9124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6848     |\n",
      "|    total_timesteps  | 37213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00728  |\n",
      "|    n_updates        | 9178     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6876     |\n",
      "|    total_timesteps  | 37487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 9246     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_37500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_37500_steps.pkl\n",
      "Eval num_timesteps=37500, episode_reward=88.40 +/- 8.64\n",
      "Episode length: 88.40 +/- 8.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 88.4     |\n",
      "|    mean_reward      | 88.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 9249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6938     |\n",
      "|    total_timesteps  | 37714    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00794  |\n",
      "|    n_updates        | 9303     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 6966     |\n",
      "|    total_timesteps  | 37981    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 9370     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_38000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_38000_steps.pkl\n",
      "Eval num_timesteps=38000, episode_reward=147.40 +/- 63.93\n",
      "Episode length: 147.40 +/- 63.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 147      |\n",
      "|    mean_reward      | 147      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7049     |\n",
      "|    total_timesteps  | 38289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00296  |\n",
      "|    n_updates        | 9447     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7071     |\n",
      "|    total_timesteps  | 38493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 9498     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_38500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_38500_steps.pkl\n",
      "Eval num_timesteps=38500, episode_reward=123.20 +/- 19.53\n",
      "Episode length: 123.20 +/- 19.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 123      |\n",
      "|    mean_reward      | 123      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 9499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7148     |\n",
      "|    total_timesteps  | 38736    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 9558     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7174     |\n",
      "|    total_timesteps  | 38970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 9617     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_39000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_39000_steps.pkl\n",
      "Eval num_timesteps=39000, episode_reward=85.00 +/- 9.53\n",
      "Episode length: 85.00 +/- 9.53\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 85       |\n",
      "|    mean_reward      | 85       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 9624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7237     |\n",
      "|    total_timesteps  | 39207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 9676     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7263     |\n",
      "|    total_timesteps  | 39456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 9738     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_39500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_39500_steps.pkl\n",
      "Eval num_timesteps=39500, episode_reward=99.80 +/- 15.77\n",
      "Episode length: 99.80 +/- 15.77\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 99.8     |\n",
      "|    mean_reward      | 99.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0702   |\n",
      "|    n_updates        | 9749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7336     |\n",
      "|    total_timesteps  | 39758    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 9814     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_40000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_40000_steps.pkl\n",
      "Eval num_timesteps=40000, episode_reward=101.60 +/- 15.49\n",
      "Episode length: 101.60 +/- 15.49\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 102      |\n",
      "|    mean_reward      | 102      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7412     |\n",
      "|    total_timesteps  | 40073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0552   |\n",
      "|    n_updates        | 9893     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7435     |\n",
      "|    total_timesteps  | 40299    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 9949     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_40500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_40500_steps.pkl\n",
      "Eval num_timesteps=40500, episode_reward=136.60 +/- 50.12\n",
      "Episode length: 136.60 +/- 50.12\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 137      |\n",
      "|    mean_reward      | 137      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7514     |\n",
      "|    total_timesteps  | 40573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 10018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7539     |\n",
      "|    total_timesteps  | 40796    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0609   |\n",
      "|    n_updates        | 10073    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_41000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_41000_steps.pkl\n",
      "Eval num_timesteps=41000, episode_reward=122.60 +/- 18.18\n",
      "Episode length: 122.60 +/- 18.18\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 123      |\n",
      "|    mean_reward      | 123      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 10124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7621     |\n",
      "|    total_timesteps  | 41132    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 10157    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7655     |\n",
      "|    total_timesteps  | 41457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 10239    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_41500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_41500_steps.pkl\n",
      "Eval num_timesteps=41500, episode_reward=99.60 +/- 1.20\n",
      "Episode length: 99.60 +/- 1.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 99.6     |\n",
      "|    mean_reward      | 99.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 10249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7730     |\n",
      "|    total_timesteps  | 41813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 10328    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_42000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_42000_steps.pkl\n",
      "Eval num_timesteps=42000, episode_reward=118.80 +/- 15.38\n",
      "Episode length: 118.80 +/- 15.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 119      |\n",
      "|    mean_reward      | 119      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0946   |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 68.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7810     |\n",
      "|    total_timesteps  | 42158    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00855  |\n",
      "|    n_updates        | 10414    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 68.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7839     |\n",
      "|    total_timesteps  | 42437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 10484    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_42500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_42500_steps.pkl\n",
      "Eval num_timesteps=42500, episode_reward=124.40 +/- 18.51\n",
      "Episode length: 124.40 +/- 18.51\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 124      |\n",
      "|    mean_reward      | 124      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 10499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 68.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7906     |\n",
      "|    total_timesteps  | 42665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 10541    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 7930     |\n",
      "|    total_timesteps  | 42897    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 10599    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_43000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_43000_steps.pkl\n",
      "Eval num_timesteps=43000, episode_reward=104.80 +/- 20.87\n",
      "Episode length: 104.80 +/- 20.87\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0558   |\n",
      "|    n_updates        | 10624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 68.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8000     |\n",
      "|    total_timesteps  | 43159    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 10664    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8026     |\n",
      "|    total_timesteps  | 43409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 10727    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_43500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_43500_steps.pkl\n",
      "Eval num_timesteps=43500, episode_reward=124.20 +/- 29.94\n",
      "Episode length: 124.20 +/- 29.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 124      |\n",
      "|    mean_reward      | 124      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 10749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8103     |\n",
      "|    total_timesteps  | 43710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0918   |\n",
      "|    n_updates        | 10802    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.6     |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8129     |\n",
      "|    total_timesteps  | 43975    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 10868    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_44000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_44000_steps.pkl\n",
      "Eval num_timesteps=44000, episode_reward=101.20 +/- 15.90\n",
      "Episode length: 101.20 +/- 15.90\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 101      |\n",
      "|    mean_reward      | 101      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00973  |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8205     |\n",
      "|    total_timesteps  | 44322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 10955    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_44500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/model_replay_buffer_44500_steps.pkl\n",
      "Eval num_timesteps=44500, episode_reward=97.80 +/- 20.69\n",
      "Episode length: 97.80 +/- 20.69\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 97.8     |\n",
      "|    mean_reward      | 97.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0303   |\n",
      "|    n_updates        | 10999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 68.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8271     |\n",
      "|    total_timesteps  | 44601    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0722   |\n",
      "|    n_updates        | 11025    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 68.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 5        |\n",
      "|    time_elapsed     | 8296     |\n",
      "|    total_timesteps  | 44837    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 11084    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/model_45000_steps.zip\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16736\\1494181842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Começa o treinamento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    263\u001b[0m     ) -> SelfDQN:\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         return super().learn(\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[0;32m    335\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;31m# Only stop training if return value is False, not when it is None.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mRolloutReturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_collected_steps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_collected_episodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;31m# If model has a replay buffer, save it too\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mreplay_buffer_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"replay_buffer_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplay_buffer_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Saving model replay buffer checkpoint to {replay_buffer_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36msave_replay_buffer\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m    233\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The replay buffer is not defined\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0msave_to_pkl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     def load_replay_buffer(\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py\u001b[0m in \u001b[0;36msave_to_pkl\u001b[1;34m(path, obj, verbose)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;31m# Use protocol>=4 to support saving replay buffers >= 4Gb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;31m# See https://docs.python.org/3/library/pickle.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "#Começa o treinamento\n",
    "model.learn(total_timesteps=45000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_16736\\1759824243.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Total Reward for episode 0 is 87\n",
      "Total Reward for episode 1 is 88\n",
      "Total Reward for episode 2 is 126\n",
      "Total Reward for episode 3 is 90\n",
      "Total Reward for episode 4 is 83\n"
     ]
    }
   ],
   "source": [
    "test_env = WebGame()\n",
    "model = get_model()\n",
    "model.load('checkpoints/best_model') \n",
    "\n",
    "for episode in range(5): \n",
    "    obs = test_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = test_env.step(action)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dffd427787c0c302\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dffd427787c0c302\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/DQN_25/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9105c753ba2e810590fbe03dc7a47b222fde04124da1bb9f952ac899bb56b210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
