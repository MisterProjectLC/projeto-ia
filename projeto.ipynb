{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dependências do Projeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in e:\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in e:\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in e:\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in e:\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in e:\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "#Instalando o pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in e:\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: mouseinfo in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pymsgbox in e:\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in e:\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pyrect in e:\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in e:\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Caso não consiga pydirectinput\n",
    "%pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in e:\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: protobuf==3.20.* in e:\\anaconda3\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.5.2)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.11 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.12.0)\n",
      "Requirement already satisfied: psutil in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: opencv-python in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: ale-py==0.7.4 in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (13.3.1)\n",
      "Requirement already satisfied: importlib-resources in e:\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in e:\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.5.4)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda3\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.16.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (63.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in e:\\anaconda3\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: libtorrent in e:\\anaconda3\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Biblioteca de aprendizado por reforço\n",
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mss in e:\\anaconda3\\lib\\site-packages (7.0.1)\n",
      "Requirement already satisfied: pydirectinput in e:\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: pytesseract in e:\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (e:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install mss pydirectinput pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para captura de tela\n",
    "from mss import mss\n",
    "#import pyautogui #para comandos de teclado\n",
    "import cv2 \n",
    "#Tratamentos dos frames\n",
    "import numpy as np \n",
    "import pyautogui\n",
    "#Framework intermediário paara trabalhar com as imagens\n",
    "#import pytesseract #para extrair o game over da imagem\n",
    "from matplotlib import pyplot as plt #Visualizando resultados\n",
    "import time\n",
    "from PIL import Image\n",
    "#Coisas para construir o ambinete\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete, Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import base64\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Construindo o Ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe para definir o ambiente\n",
    "class WebGame(Env):\n",
    "    #ESSAS FUNÇÃO SÃO NECESSÁRIAS POR CONTA DO GYM\n",
    "    #Função responsavel pela inicialização do ambiente;\n",
    "    #Portanto onde ficam todas as variaveis do ambiente, configuração das ações e da observação \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Configuração do tempo\n",
    "        self.print_time = .005\n",
    "        self.wait_time = .015\n",
    "        \n",
    "        #Configuração do espaço\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8)\n",
    "        #self.observation_space = Dict({\n",
    "        #    \"print\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "        #    \"print2\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "        #    \"print3\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "            #\"print4\":Box(low=0, high=255, shape=(1,83,200), dtype=np.uint8),\n",
    "        #    \"score\":Box(low=0, high=10000, shape=(1,), dtype=np.uint8),\n",
    "        #                              })\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "        #Variavei para a captura de tela\n",
    "        self.screen_cap = mss() #Lib de captura de tela\n",
    "        self.game_location = {\"top\": 300, \"left\": 0, \"width\": 650, \"height\": 500} #Área do monitor com \n",
    "        self.game_done = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 640}\n",
    "\n",
    "        self.chromedriver_path = \"./chromedriver.exe\"\n",
    "        _chrome_options = webdriver.ChromeOptions()\n",
    "        _chrome_options.add_argument(\"--mute-audio\")\n",
    "        _chrome_options.add_argument(\"--disable-gpu\")\n",
    "        self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n",
    "\n",
    "        self.first_image = np.zeros(5)\n",
    "        self.last_image = np.zeros((500,650,3))\n",
    "        \n",
    "        #Dicionário de ações\n",
    "        self.action_dict = {\n",
    "            0:Keys.ARROW_DOWN,\n",
    "            1:Keys.ARROW_UP,\n",
    "            2:'nothing'\n",
    "        }\n",
    "\n",
    "    #Função responsavel por passar as ações pro jogo, para fazer algo pro jogo\n",
    "    def step(self, action):\n",
    "        # Se ação escolhida for um dos botões, realizar a ação.\n",
    "        if action != 2:\n",
    "            self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(self.action_dict[int(action)])\n",
    "        \n",
    "        #Checa a próxima ação\n",
    "        observation = self.get_observation()\n",
    "        #Todas as ações tem que verificar se a ação acabou\n",
    "        done, done_cap = self.get_done() \n",
    "        \n",
    "        #Pegando o score do jogo\n",
    "        score = self.get_score()\n",
    "        #Ganhamos 1 ponto por cada frame que estamos vivos.\n",
    "        reward = 1\n",
    "        #É um dicionário de informações que retornam através do que a gente precisa\n",
    "        info = {\n",
    "            'score':score\n",
    "        }\n",
    "\n",
    "        time.sleep(self.wait_time)\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "        \n",
    "\n",
    "    #Função para a visualização do jogo:\n",
    "    def render(self, mode: str='human'):\n",
    "        img = cv2.cvtColor(self._get_image(), cv2.COLOR_BGR2RGB)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "        # cv2.imshow('Game', np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     self.close()\n",
    "\n",
    "    #Função responsavel por recomeçar o jogo\n",
    "    def reset(self):\n",
    "        #Try catch precisa existir pq toda a vez q o selenium detecta que ele viu o chrome dino,\n",
    "        #ele dispara um erro que esta sem internet.\n",
    "        try:\n",
    "            self._driver.get('chrome://dino')\n",
    "            \n",
    "        except WebDriverException:\n",
    "            pass\n",
    "        WebDriverWait(self._driver, 10).until(\n",
    "            EC.presence_of_element_located((\n",
    "                By.CLASS_NAME, \n",
    "                \"runner-canvas\"\n",
    "            ))\n",
    "        )\n",
    "        self._driver.implicitly_wait(0.5)\n",
    "        self._driver.find_elements(By.TAG_NAME, \"body\")[0].send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "        return self.get_observation()\n",
    "\n",
    "    #FUNÇÕES CUSTOM\n",
    "    #Fecha a parte de visualização\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        #shape = np.zeros(1)\n",
    "        #shape[0] = int(score)\n",
    "        return int(score)\n",
    "    \n",
    "    def get_score_shape(self):\n",
    "        shape = np.zeros(1)\n",
    "        shape[0] = int(self.get_score())\n",
    "        return shape\n",
    "    \n",
    "    def get_img(self):\n",
    "        LEADING_TEXT = \"data:image/png;base64,\"\n",
    "        canvas = self._driver.execute_script(\"return document.querySelector('canvas.runner-canvas').toDataURL()\")\n",
    "        img = canvas[len(LEADING_TEXT):]\n",
    "        img_data = np.array(Image.open(BytesIO(base64.b64decode(img))))\n",
    "        return img_data \n",
    "        # img = self._driver.execute_script()\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_print(self): \n",
    "\n",
    "        #img = numpy.array(self.screen_cap.grab(game_location))[:,:,3].astype(np.uint8)\n",
    "        raw = np.array(self.get_img())[:,:,:3].astype(np.uint8)\n",
    "        img = raw[:200,:400]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (200,83))\n",
    "        channel = np.reshape(resized, (1,83,200))\n",
    "        \n",
    "        self.first_image = self.last_image\n",
    "        self.last_image = raw\n",
    "        \n",
    "        return channel\n",
    "    \n",
    "    #Função responsavel por pegar a imagem do jogo e tratar da forma necessária.\n",
    "    def get_observation(self): \n",
    "        #print1 = self.get_print()\n",
    "        #self._driver.implicitly_wait(self.print_time)\n",
    "        #print2 = self.get_print()\n",
    "        #self._driver.implicitly_wait(self.print_time)\n",
    "        #return {\"print\":print1, \"print2\":print2, \"print3\":self.get_print(), \"score\":self.get_score_shape() }\n",
    "        return self.get_print()\n",
    "\n",
    "\n",
    "    #Função para pegar o texto de fim de jogo:\n",
    "    def get_done(self):\n",
    "        #Se as duas imagens iniciais forem iguais acabou jogo\n",
    "        done = False\n",
    "        #Colando a primeira condição devido ao fator de que as formas diferentes estavam dando problema na comparação devido ao np.all\n",
    "        \n",
    "        if self.first_image.shape != self.last_image.shape:\n",
    "            return done, self.last_image\n",
    "\n",
    "        if np.all(np.equal(self.first_image, self.last_image)) and not self._driver.execute_script(\"return Runner.instance_.playing\"):\n",
    "            done = True\n",
    "        \n",
    "        return done, self.last_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback, CallbackList\n",
    "# Verificando se o ambiente é válido para fazer as coisa\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO, DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack,SubprocVecEnv\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.logger import Figure, configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_11700\\830487098.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#env_lambda = lambda: WebGame()\n",
    "#env2 = SubprocVecEnv([env_lambda for i in range(4)])\n",
    "env2 = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criandos as pastas para que funcione.\n",
    "CHECKPOINT_DIR = './checkpoints/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=500,\n",
    "  save_path=CHECKPOINT_DIR,\n",
    "  name_prefix=\"dqn_single_single_model\",\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    "    verbose=2\n",
    ")\n",
    "eval_callback = EvalCallback(env2, best_model_save_path=CHECKPOINT_DIR,\n",
    "                             log_path=LOG_DIR, eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "callback = CallbackList([checkpoint_callback, eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #model = PPO('MultiInputPolicy', env2, tensorboard_log=LOG_DIR, learning_rate=0.005, verbose=2, policy_kwargs=dict(normalize_images=False))\n",
    "    model = DQN('CnnPolicy', env2, tensorboard_log=LOG_DIR, verbose=2, buffer_size=12000, learning_rate=0.0006, \n",
    "        learning_starts=500, exploration_fraction=0.4, exploration_initial_eps=0.9, exploration_final_eps=0.05,\n",
    "                policy_kwargs=dict(normalize_images=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/DQN_23\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_500_steps.pkl\n",
      "Eval num_timesteps=500, episode_reward=159.00 +/- 2.45\n",
      "Episode length: 159.00 +/- 2.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 159      |\n",
      "|    mean_reward      | 159      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 147      |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 587      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0357   |\n",
      "|    n_updates        | 21       |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_1000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_1000_steps.pkl\n",
      "Eval num_timesteps=1000, episode_reward=168.20 +/- 27.56\n",
      "Episode length: 168.20 +/- 27.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 168      |\n",
      "|    mean_reward      | 168      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 124      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 136      |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 1090     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 147      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 1468     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 241      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_1500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_1500_steps.pkl\n",
      "Eval num_timesteps=1500, episode_reward=110.80 +/- 3.31\n",
      "Episode length: 110.80 +/- 3.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 111      |\n",
      "|    mean_reward      | 111      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 1859     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 339      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_2000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_2000_steps.pkl\n",
      "Eval num_timesteps=2000, episode_reward=117.20 +/- 2.71\n",
      "Episode length: 117.20 +/- 2.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 117      |\n",
      "|    mean_reward      | 117      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 2254     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 438      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_2500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_2500_steps.pkl\n",
      "Eval num_timesteps=2500, episode_reward=137.20 +/- 11.75\n",
      "Episode length: 137.20 +/- 11.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 137      |\n",
      "|    mean_reward      | 137      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 2693     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 548      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_3000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_3000_steps.pkl\n",
      "Eval num_timesteps=3000, episode_reward=146.80 +/- 24.36\n",
      "Episode length: 146.80 +/- 24.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 147      |\n",
      "|    mean_reward      | 147      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 3086     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 646      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total_timesteps  | 3451     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 737      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_3500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_3500_steps.pkl\n",
      "Eval num_timesteps=3500, episode_reward=149.00 +/- 12.21\n",
      "Episode length: 149.00 +/- 12.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 149      |\n",
      "|    mean_reward      | 149      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 444      |\n",
      "|    total_timesteps  | 3858     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 839      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_4000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_4000_steps.pkl\n",
      "Eval num_timesteps=4000, episode_reward=142.40 +/- 16.45\n",
      "Episode length: 142.40 +/- 16.45\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 142      |\n",
      "|    mean_reward      | 142      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 504      |\n",
      "|    total_timesteps  | 4282     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 945      |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_4500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_4500_steps.pkl\n",
      "Eval num_timesteps=4500, episode_reward=126.00 +/- 4.38\n",
      "Episode length: 126.00 +/- 4.38\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 126      |\n",
      "|    mean_reward      | 126      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 557      |\n",
      "|    total_timesteps  | 4682     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 1045     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_5000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_5000_steps.pkl\n",
      "Eval num_timesteps=5000, episode_reward=127.60 +/- 32.23\n",
      "Episode length: 127.60 +/- 32.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 128      |\n",
      "|    mean_reward      | 128      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 615      |\n",
      "|    total_timesteps  | 5094     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 1148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 639      |\n",
      "|    total_timesteps  | 5478     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 1244     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_5500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_5500_steps.pkl\n",
      "Eval num_timesteps=5500, episode_reward=138.00 +/- 15.21\n",
      "Episode length: 138.00 +/- 15.21\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 138      |\n",
      "|    mean_reward      | 138      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 1249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 698      |\n",
      "|    total_timesteps  | 5942     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 1360     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_6000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_6000_steps.pkl\n",
      "Eval num_timesteps=6000, episode_reward=125.80 +/- 15.78\n",
      "Episode length: 125.80 +/- 15.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 126      |\n",
      "|    mean_reward      | 126      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.6      |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 754      |\n",
      "|    total_timesteps  | 6348     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 1461     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_6500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_6500_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6500, episode_reward=134.60 +/- 12.01\n",
      "Episode length: 134.60 +/- 12.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 135      |\n",
      "|    mean_reward      | 135      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 811      |\n",
      "|    total_timesteps  | 6756     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 1563     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_7000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_7000_steps.pkl\n",
      "Eval num_timesteps=7000, episode_reward=157.00 +/- 23.22\n",
      "Episode length: 157.00 +/- 23.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 157      |\n",
      "|    mean_reward      | 157      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 1624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 873      |\n",
      "|    total_timesteps  | 7190     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 1672     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_7500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_7500_steps.pkl\n",
      "Eval num_timesteps=7500, episode_reward=145.20 +/- 16.22\n",
      "Episode length: 145.20 +/- 16.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 145      |\n",
      "|    mean_reward      | 145      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00877  |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 931      |\n",
      "|    total_timesteps  | 7608     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 1776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 952      |\n",
      "|    total_timesteps  | 7945     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 1861     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_8000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_8000_steps.pkl\n",
      "Eval num_timesteps=8000, episode_reward=128.40 +/- 12.27\n",
      "Episode length: 128.40 +/- 12.27\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 128      |\n",
      "|    mean_reward      | 128      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1010     |\n",
      "|    total_timesteps  | 8347     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 1961     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_8500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_8500_steps.pkl\n",
      "Eval num_timesteps=8500, episode_reward=134.60 +/- 16.16\n",
      "Episode length: 134.60 +/- 16.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 135      |\n",
      "|    mean_reward      | 135      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0337   |\n",
      "|    n_updates        | 1999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1068     |\n",
      "|    total_timesteps  | 8746     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 2061     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_9000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_9000_steps.pkl\n",
      "Eval num_timesteps=9000, episode_reward=146.80 +/- 6.76\n",
      "Episode length: 146.80 +/- 6.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 147      |\n",
      "|    mean_reward      | 147      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 2124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1133     |\n",
      "|    total_timesteps  | 9298     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 2199     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_9500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_9500_steps.pkl\n",
      "Eval num_timesteps=9500, episode_reward=136.40 +/- 5.35\n",
      "Episode length: 136.40 +/- 5.35\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 136      |\n",
      "|    mean_reward      | 136      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9500     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1185     |\n",
      "|    total_timesteps  | 9674     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 2293     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_10000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_10000_steps.pkl\n",
      "Eval num_timesteps=10000, episode_reward=128.60 +/- 6.47\n",
      "Episode length: 128.60 +/- 6.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 129      |\n",
      "|    mean_reward      | 129      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1240     |\n",
      "|    total_timesteps  | 10088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0791   |\n",
      "|    n_updates        | 2396     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1261     |\n",
      "|    total_timesteps  | 10430    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 2482     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_10500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_10500_steps.pkl\n",
      "Eval num_timesteps=10500, episode_reward=131.40 +/- 7.36\n",
      "Episode length: 131.40 +/- 7.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 131      |\n",
      "|    mean_reward      | 131      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 2499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 102      |\n",
      "|    ep_rew_mean      | 102      |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1317     |\n",
      "|    total_timesteps  | 10820    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00966  |\n",
      "|    n_updates        | 2579     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_11000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_11000_steps.pkl\n",
      "Eval num_timesteps=11000, episode_reward=137.40 +/- 10.33\n",
      "Episode length: 137.40 +/- 10.33\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 137      |\n",
      "|    mean_reward      | 137      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 2624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1371     |\n",
      "|    total_timesteps  | 11159    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 2664     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_11500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_11500_steps.pkl\n",
      "Eval num_timesteps=11500, episode_reward=153.80 +/- 10.03\n",
      "Episode length: 153.80 +/- 10.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 154      |\n",
      "|    mean_reward      | 154      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 2749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1432     |\n",
      "|    total_timesteps  | 11570    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 2767     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 100      |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1455     |\n",
      "|    total_timesteps  | 11888    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 2846     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_12000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_12000_steps.pkl\n",
      "Eval num_timesteps=12000, episode_reward=92.60 +/- 11.67\n",
      "Episode length: 92.60 +/- 11.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.6     |\n",
      "|    mean_reward      | 92.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 99.7     |\n",
      "|    ep_rew_mean      | 99.7     |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1511     |\n",
      "|    total_timesteps  | 12227    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 2931     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_12500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_12500_steps.pkl\n",
      "Eval num_timesteps=12500, episode_reward=93.00 +/- 8.05\n",
      "Episode length: 93.00 +/- 8.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 93       |\n",
      "|    mean_reward      | 93       |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 2999     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | 98.8     |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1568     |\n",
      "|    total_timesteps  | 12574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 3018     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.8     |\n",
      "|    ep_rew_mean      | 97.8     |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1590     |\n",
      "|    total_timesteps  | 12868    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 3091     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_13000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_13000_steps.pkl\n",
      "Eval num_timesteps=13000, episode_reward=116.00 +/- 3.74\n",
      "Episode length: 116.00 +/- 3.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 116      |\n",
      "|    mean_reward      | 116      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00637  |\n",
      "|    n_updates        | 3124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | 98       |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1646     |\n",
      "|    total_timesteps  | 13248    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00793  |\n",
      "|    n_updates        | 3186     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_13500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_13500_steps.pkl\n",
      "Eval num_timesteps=13500, episode_reward=113.40 +/- 6.25\n",
      "Episode length: 113.40 +/- 6.25\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 113      |\n",
      "|    mean_reward      | 113      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 13500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00888  |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98       |\n",
      "|    ep_rew_mean      | 98       |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1703     |\n",
      "|    total_timesteps  | 13662    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 3290     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_14000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_14000_steps.pkl\n",
      "Eval num_timesteps=14000, episode_reward=105.20 +/- 2.71\n",
      "Episode length: 105.20 +/- 2.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.239    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 3374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.1     |\n",
      "|    ep_rew_mean      | 98.1     |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1758     |\n",
      "|    total_timesteps  | 14090    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 3397     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | 97.7     |\n",
      "|    exploration_rate | 0.218    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1781     |\n",
      "|    total_timesteps  | 14452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 3487     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_14500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_14500_steps.pkl\n",
      "Eval num_timesteps=14500, episode_reward=110.60 +/- 3.20\n",
      "Episode length: 110.60 +/- 3.20\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 111      |\n",
      "|    mean_reward      | 111      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 14500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00852  |\n",
      "|    n_updates        | 3499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.4     |\n",
      "|    ep_rew_mean      | 97.4     |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1835     |\n",
      "|    total_timesteps  | 14832    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 3582     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_15000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_15000_steps.pkl\n",
      "Eval num_timesteps=15000, episode_reward=114.00 +/- 4.94\n",
      "Episode length: 114.00 +/- 4.94\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 114      |\n",
      "|    mean_reward      | 114      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0083   |\n",
      "|    n_updates        | 3624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | 97.7     |\n",
      "|    exploration_rate | 0.18     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1891     |\n",
      "|    total_timesteps  | 15246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 3686     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_15500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_15500_steps.pkl\n",
      "Eval num_timesteps=15500, episode_reward=129.40 +/- 3.88\n",
      "Episode length: 129.40 +/- 3.88\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 129      |\n",
      "|    mean_reward      | 129      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 3749     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.6     |\n",
      "|    ep_rew_mean      | 96.6     |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1944     |\n",
      "|    total_timesteps  | 15602    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 3775     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_16000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_16000_steps.pkl\n",
      "Eval num_timesteps=16000, episode_reward=135.40 +/- 2.06\n",
      "Episode length: 135.40 +/- 2.06\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 135      |\n",
      "|    mean_reward      | 135      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.3     |\n",
      "|    ep_rew_mean      | 97.3     |\n",
      "|    exploration_rate | 0.141    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2004     |\n",
      "|    total_timesteps  | 16082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00685  |\n",
      "|    n_updates        | 3895     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.8     |\n",
      "|    ep_rew_mean      | 96.8     |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2029     |\n",
      "|    total_timesteps  | 16434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 3983     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_16500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_16500_steps.pkl\n",
      "Eval num_timesteps=16500, episode_reward=107.00 +/- 3.74\n",
      "Episode length: 107.00 +/- 3.74\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 107      |\n",
      "|    mean_reward      | 107      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 16500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 3999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.7     |\n",
      "|    ep_rew_mean      | 96.7     |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2085     |\n",
      "|    total_timesteps  | 16861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00584  |\n",
      "|    n_updates        | 4090     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_17000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_17000_steps.pkl\n",
      "Eval num_timesteps=17000, episode_reward=154.60 +/- 2.50\n",
      "Episode length: 154.60 +/- 2.50\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 155      |\n",
      "|    mean_reward      | 155      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0973   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 4124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.6     |\n",
      "|    ep_rew_mean      | 96.6     |\n",
      "|    exploration_rate | 0.0845   |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2141     |\n",
      "|    total_timesteps  | 17270    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00804  |\n",
      "|    n_updates        | 4192     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_17500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_17500_steps.pkl\n",
      "Eval num_timesteps=17500, episode_reward=130.20 +/- 14.78\n",
      "Episode length: 130.20 +/- 14.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0737   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 17500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 4249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.5     |\n",
      "|    ep_rew_mean      | 97.5     |\n",
      "|    exploration_rate | 0.0645   |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2201     |\n",
      "|    total_timesteps  | 17694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 4298     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_18000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_18000_steps.pkl\n",
      "Eval num_timesteps=18000, episode_reward=114.20 +/- 7.44\n",
      "Episode length: 114.20 +/- 7.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 114      |\n",
      "|    mean_reward      | 114      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 4374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97.7     |\n",
      "|    ep_rew_mean      | 97.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2258     |\n",
      "|    total_timesteps  | 18114    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 4403     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.9     |\n",
      "|    ep_rew_mean      | 96.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2279     |\n",
      "|    total_timesteps  | 18434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 4483     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_18500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_18500_steps.pkl\n",
      "Eval num_timesteps=18500, episode_reward=114.60 +/- 8.64\n",
      "Episode length: 114.60 +/- 8.64\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 115      |\n",
      "|    mean_reward      | 115      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 18500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 4499     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.8     |\n",
      "|    ep_rew_mean      | 94.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2338     |\n",
      "|    total_timesteps  | 18775    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00908  |\n",
      "|    n_updates        | 4568     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_19000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_19000_steps.pkl\n",
      "Eval num_timesteps=19000, episode_reward=83.40 +/- 3.01\n",
      "Episode length: 83.40 +/- 3.01\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 83.4     |\n",
      "|    mean_reward      | 83.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00648  |\n",
      "|    n_updates        | 4624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.9     |\n",
      "|    ep_rew_mean      | 93.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2392     |\n",
      "|    total_timesteps  | 19067    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 4641     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.5     |\n",
      "|    ep_rew_mean      | 92.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2415     |\n",
      "|    total_timesteps  | 19338    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00815  |\n",
      "|    n_updates        | 4709     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_19500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_19500_steps.pkl\n",
      "Eval num_timesteps=19500, episode_reward=109.20 +/- 14.73\n",
      "Episode length: 109.20 +/- 14.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 109      |\n",
      "|    mean_reward      | 109      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 19500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 4749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.1     |\n",
      "|    ep_rew_mean      | 92.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2472     |\n",
      "|    total_timesteps  | 19636    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 4783     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | 90.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2495     |\n",
      "|    total_timesteps  | 19910    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 4852     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_20000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_20000_steps.pkl\n",
      "Eval num_timesteps=20000, episode_reward=98.40 +/- 3.98\n",
      "Episode length: 98.40 +/- 3.98\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 98.4     |\n",
      "|    mean_reward      | 98.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 4874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.4     |\n",
      "|    ep_rew_mean      | 90.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2550     |\n",
      "|    total_timesteps  | 20197    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.057    |\n",
      "|    n_updates        | 4924     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89       |\n",
      "|    ep_rew_mean      | 89       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2573     |\n",
      "|    total_timesteps  | 20472    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 4992     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_20500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_20500_steps.pkl\n",
      "Eval num_timesteps=20500, episode_reward=105.60 +/- 8.04\n",
      "Episode length: 105.60 +/- 8.04\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 106      |\n",
      "|    mean_reward      | 106      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.2     |\n",
      "|    ep_rew_mean      | 89.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2639     |\n",
      "|    total_timesteps  | 20805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 5076     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_21000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_21000_steps.pkl\n",
      "Eval num_timesteps=21000, episode_reward=92.20 +/- 7.36\n",
      "Episode length: 92.20 +/- 7.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92.2     |\n",
      "|    mean_reward      | 92.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 5124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.2     |\n",
      "|    ep_rew_mean      | 89.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2701     |\n",
      "|    total_timesteps  | 21143    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00971  |\n",
      "|    n_updates        | 5160     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.5     |\n",
      "|    ep_rew_mean      | 88.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2724     |\n",
      "|    total_timesteps  | 21422    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 5230     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_21500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_21500_steps.pkl\n",
      "Eval num_timesteps=21500, episode_reward=119.20 +/- 18.82\n",
      "Episode length: 119.20 +/- 18.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 119      |\n",
      "|    mean_reward      | 119      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 21500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 5249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.2     |\n",
      "|    ep_rew_mean      | 90.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2787     |\n",
      "|    total_timesteps  | 21890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 5347     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_22000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_22000_steps.pkl\n",
      "Eval num_timesteps=22000, episode_reward=179.20 +/- 9.17\n",
      "Episode length: 179.20 +/- 9.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 179      |\n",
      "|    mean_reward      | 179      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.4     |\n",
      "|    ep_rew_mean      | 90.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2845     |\n",
      "|    total_timesteps  | 22286    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 5446     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_22500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_22500_steps.pkl\n",
      "Eval num_timesteps=22500, episode_reward=145.60 +/- 36.30\n",
      "Episode length: 145.60 +/- 36.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 146      |\n",
      "|    mean_reward      | 146      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 22500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0337   |\n",
      "|    n_updates        | 5499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.8     |\n",
      "|    ep_rew_mean      | 90.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2907     |\n",
      "|    total_timesteps  | 22737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00479  |\n",
      "|    n_updates        | 5559     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_23000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_23000_steps.pkl\n",
      "Eval num_timesteps=23000, episode_reward=169.40 +/- 31.32\n",
      "Episode length: 169.40 +/- 31.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 169      |\n",
      "|    mean_reward      | 169      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 5624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | 90.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 2977     |\n",
      "|    total_timesteps  | 23178    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00951  |\n",
      "|    n_updates        | 5669     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_23500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_23500_steps.pkl\n",
      "Eval num_timesteps=23500, episode_reward=128.40 +/- 22.08\n",
      "Episode length: 128.40 +/- 22.08\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 128      |\n",
      "|    mean_reward      | 128      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 23500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 5749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.7     |\n",
      "|    ep_rew_mean      | 91.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3039     |\n",
      "|    total_timesteps  | 23626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 5781     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_24000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_24000_steps.pkl\n",
      "Eval num_timesteps=24000, episode_reward=201.60 +/- 29.28\n",
      "Episode length: 201.60 +/- 29.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 202      |\n",
      "|    mean_reward      | 202      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 5874     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.8     |\n",
      "|    ep_rew_mean      | 92.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3113     |\n",
      "|    total_timesteps  | 24115    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00629  |\n",
      "|    n_updates        | 5903     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.4     |\n",
      "|    ep_rew_mean      | 92.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3137     |\n",
      "|    total_timesteps  | 24487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 5996     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_24500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_24500_steps.pkl\n",
      "Eval num_timesteps=24500, episode_reward=183.40 +/- 30.96\n",
      "Episode length: 183.40 +/- 30.96\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 183      |\n",
      "|    mean_reward      | 183      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 24500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00779  |\n",
      "|    n_updates        | 5999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | 93       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3204     |\n",
      "|    total_timesteps  | 24903    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 6100     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_25000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_25000_steps.pkl\n",
      "Eval num_timesteps=25000, episode_reward=138.80 +/- 28.92\n",
      "Episode length: 138.80 +/- 28.92\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 139      |\n",
      "|    mean_reward      | 139      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 6124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.1     |\n",
      "|    ep_rew_mean      | 92.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3264     |\n",
      "|    total_timesteps  | 25295    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00842  |\n",
      "|    n_updates        | 6198     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_25500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_25500_steps.pkl\n",
      "Eval num_timesteps=25500, episode_reward=161.40 +/- 32.63\n",
      "Episode length: 161.40 +/- 32.63\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 161      |\n",
      "|    mean_reward      | 161      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 6249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.5     |\n",
      "|    ep_rew_mean      | 92.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3332     |\n",
      "|    total_timesteps  | 25679    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 6294     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_26000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_26000_steps.pkl\n",
      "Eval num_timesteps=26000, episode_reward=141.40 +/- 31.89\n",
      "Episode length: 141.40 +/- 31.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 141      |\n",
      "|    mean_reward      | 141      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00706  |\n",
      "|    n_updates        | 6374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.4     |\n",
      "|    ep_rew_mean      | 92.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3393     |\n",
      "|    total_timesteps  | 26102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 6400     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.8     |\n",
      "|    ep_rew_mean      | 91.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3416     |\n",
      "|    total_timesteps  | 26450    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00881  |\n",
      "|    n_updates        | 6487     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_26500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_26500_steps.pkl\n",
      "Eval num_timesteps=26500, episode_reward=129.40 +/- 8.26\n",
      "Episode length: 129.40 +/- 8.26\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 129      |\n",
      "|    mean_reward      | 129      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 26500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00591  |\n",
      "|    n_updates        | 6499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.6     |\n",
      "|    ep_rew_mean      | 91.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3475     |\n",
      "|    total_timesteps  | 26852    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 6587     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_27000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_27000_steps.pkl\n",
      "Eval num_timesteps=27000, episode_reward=129.40 +/- 7.28\n",
      "Episode length: 129.40 +/- 7.28\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 129      |\n",
      "|    mean_reward      | 129      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00345  |\n",
      "|    n_updates        | 6624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.5     |\n",
      "|    ep_rew_mean      | 91.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3536     |\n",
      "|    total_timesteps  | 27260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 6689     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_27500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_27500_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=27500, episode_reward=108.60 +/- 8.80\n",
      "Episode length: 108.60 +/- 8.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 109      |\n",
      "|    mean_reward      | 109      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 27500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 6749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.6     |\n",
      "|    ep_rew_mean      | 92.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3593     |\n",
      "|    total_timesteps  | 27698    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 6799     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_28000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_28000_steps.pkl\n",
      "Eval num_timesteps=28000, episode_reward=143.20 +/- 5.56\n",
      "Episode length: 143.20 +/- 5.56\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 143      |\n",
      "|    mean_reward      | 143      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 6874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.2     |\n",
      "|    ep_rew_mean      | 93.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3656     |\n",
      "|    total_timesteps  | 28094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 6898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.8     |\n",
      "|    ep_rew_mean      | 93.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3679     |\n",
      "|    total_timesteps  | 28450    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00702  |\n",
      "|    n_updates        | 6987     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_28500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_28500_steps.pkl\n",
      "Eval num_timesteps=28500, episode_reward=163.40 +/- 21.17\n",
      "Episode length: 163.40 +/- 21.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 163      |\n",
      "|    mean_reward      | 163      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 28500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00565  |\n",
      "|    n_updates        | 6999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.3     |\n",
      "|    ep_rew_mean      | 95.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3744     |\n",
      "|    total_timesteps  | 28870    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0046   |\n",
      "|    n_updates        | 7092     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_29000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_29000_steps.pkl\n",
      "Eval num_timesteps=29000, episode_reward=133.80 +/- 15.61\n",
      "Episode length: 133.80 +/- 15.61\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 134      |\n",
      "|    mean_reward      | 134      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00758  |\n",
      "|    n_updates        | 7124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.1     |\n",
      "|    ep_rew_mean      | 96.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3800     |\n",
      "|    total_timesteps  | 29243    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 7185     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_29500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_29500_steps.pkl\n",
      "Eval num_timesteps=29500, episode_reward=145.20 +/- 32.05\n",
      "Episode length: 145.20 +/- 32.05\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 145      |\n",
      "|    mean_reward      | 145      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 29500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 7249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 97       |\n",
      "|    ep_rew_mean      | 97       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3861     |\n",
      "|    total_timesteps  | 29606    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 7276     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_30000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_30000_steps.pkl\n",
      "Eval num_timesteps=30000, episode_reward=168.20 +/- 17.16\n",
      "Episode length: 168.20 +/- 17.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 168      |\n",
      "|    mean_reward      | 168      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 7374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 98.8     |\n",
      "|    ep_rew_mean      | 98.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3934     |\n",
      "|    total_timesteps  | 30077    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0583   |\n",
      "|    n_updates        | 7394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 100      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 3959     |\n",
      "|    total_timesteps  | 30468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 7491     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_30500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_30500_steps.pkl\n",
      "Eval num_timesteps=30500, episode_reward=191.40 +/- 41.11\n",
      "Episode length: 191.40 +/- 41.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 191      |\n",
      "|    mean_reward      | 191      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0434   |\n",
      "|    n_updates        | 7499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4030     |\n",
      "|    total_timesteps  | 30950    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 7612     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_31000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_31000_steps.pkl\n",
      "Eval num_timesteps=31000, episode_reward=131.00 +/- 29.73\n",
      "Episode length: 131.00 +/- 29.73\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 131      |\n",
      "|    mean_reward      | 131      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00557  |\n",
      "|    n_updates        | 7624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 103      |\n",
      "|    ep_rew_mean      | 103      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4097     |\n",
      "|    total_timesteps  | 31446    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 7736     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_31500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_31500_steps.pkl\n",
      "Eval num_timesteps=31500, episode_reward=128.20 +/- 13.86\n",
      "Episode length: 128.20 +/- 13.86\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 128      |\n",
      "|    mean_reward      | 128      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 31500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 7749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4158     |\n",
      "|    total_timesteps  | 31862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 7840     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_32000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_32000_steps.pkl\n",
      "Eval num_timesteps=32000, episode_reward=166.20 +/- 29.03\n",
      "Episode length: 166.20 +/- 29.03\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 166      |\n",
      "|    mean_reward      | 166      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 7874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4227     |\n",
      "|    total_timesteps  | 32302    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 7950     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_32500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_32500_steps.pkl\n",
      "Eval num_timesteps=32500, episode_reward=199.40 +/- 19.65\n",
      "Episode length: 199.40 +/- 19.65\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 199      |\n",
      "|    mean_reward      | 199      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 32500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 7999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4294     |\n",
      "|    total_timesteps  | 32778    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 8069     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_33000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_33000_steps.pkl\n",
      "Eval num_timesteps=33000, episode_reward=130.20 +/- 7.22\n",
      "Episode length: 130.20 +/- 7.22\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 8124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4356     |\n",
      "|    total_timesteps  | 33195    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 8173     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_33500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_33500_steps.pkl\n",
      "Eval num_timesteps=33500, episode_reward=207.80 +/- 22.31\n",
      "Episode length: 207.80 +/- 22.31\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 208      |\n",
      "|    mean_reward      | 208      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 33500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 8249     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4426     |\n",
      "|    total_timesteps  | 33675    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 8293     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_34000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_34000_steps.pkl\n",
      "Eval num_timesteps=34000, episode_reward=157.00 +/- 30.23\n",
      "Episode length: 157.00 +/- 30.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 157      |\n",
      "|    mean_reward      | 157      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4488     |\n",
      "|    total_timesteps  | 34099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00831  |\n",
      "|    n_updates        | 8399     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_34500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_34500_steps.pkl\n",
      "Eval num_timesteps=34500, episode_reward=130.00 +/- 22.09\n",
      "Episode length: 130.00 +/- 22.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 130      |\n",
      "|    mean_reward      | 130      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 34500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00574  |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4551     |\n",
      "|    total_timesteps  | 34582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00962  |\n",
      "|    n_updates        | 8520     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4577     |\n",
      "|    total_timesteps  | 34994    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 8623     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_35000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_35000_steps.pkl\n",
      "Eval num_timesteps=35000, episode_reward=173.40 +/- 24.16\n",
      "Episode length: 173.40 +/- 24.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 173      |\n",
      "|    mean_reward      | 173      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00619  |\n",
      "|    n_updates        | 8624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 104      |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4640     |\n",
      "|    total_timesteps  | 35335    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00625  |\n",
      "|    n_updates        | 8708     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_35500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_35500_steps.pkl\n",
      "Eval num_timesteps=35500, episode_reward=227.20 +/- 24.93\n",
      "Episode length: 227.20 +/- 24.93\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 227      |\n",
      "|    mean_reward      | 227      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00761  |\n",
      "|    n_updates        | 8749     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 106      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4719     |\n",
      "|    total_timesteps  | 35899    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 8849     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_36000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_36000_steps.pkl\n",
      "Eval num_timesteps=36000, episode_reward=130.80 +/- 16.71\n",
      "Episode length: 130.80 +/- 16.71\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 131      |\n",
      "|    mean_reward      | 131      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4783     |\n",
      "|    total_timesteps  | 36376    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00901  |\n",
      "|    n_updates        | 8968     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_36500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_36500_steps.pkl\n",
      "Eval num_timesteps=36500, episode_reward=180.00 +/- 27.44\n",
      "Episode length: 180.00 +/- 27.44\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 180      |\n",
      "|    mean_reward      | 180      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 36500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0594   |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 107      |\n",
      "|    ep_rew_mean      | 107      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4852     |\n",
      "|    total_timesteps  | 36774    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 9068     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_37000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_37000_steps.pkl\n",
      "Eval num_timesteps=37000, episode_reward=127.20 +/- 13.67\n",
      "Episode length: 127.20 +/- 13.67\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 127      |\n",
      "|    mean_reward      | 127      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 9124     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4914     |\n",
      "|    total_timesteps  | 37258    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 9189     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_37500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_37500_steps.pkl\n",
      "Eval num_timesteps=37500, episode_reward=154.20 +/- 35.09\n",
      "Episode length: 154.20 +/- 35.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 154      |\n",
      "|    mean_reward      | 154      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 37500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 9249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 4980     |\n",
      "|    total_timesteps  | 37674    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 9293     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_38000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_38000_steps.pkl\n",
      "Eval num_timesteps=38000, episode_reward=112.20 +/- 1.17\n",
      "Episode length: 112.20 +/- 1.17\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 112      |\n",
      "|    mean_reward      | 112      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 9374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5037     |\n",
      "|    total_timesteps  | 38092    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 9397     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_38500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_38500_steps.pkl\n",
      "Eval num_timesteps=38500, episode_reward=182.60 +/- 20.78\n",
      "Episode length: 182.60 +/- 20.78\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 183      |\n",
      "|    mean_reward      | 183      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 38500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00584  |\n",
      "|    n_updates        | 9499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5110     |\n",
      "|    total_timesteps  | 38582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 9520     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5137     |\n",
      "|    total_timesteps  | 38993    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 9623     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_39000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_39000_steps.pkl\n",
      "Eval num_timesteps=39000, episode_reward=145.00 +/- 27.76\n",
      "Episode length: 145.00 +/- 27.76\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 145      |\n",
      "|    mean_reward      | 145      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 9624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5200     |\n",
      "|    total_timesteps  | 39398    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 9724     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_39500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_39500_steps.pkl\n",
      "Eval num_timesteps=39500, episode_reward=126.20 +/- 28.95\n",
      "Episode length: 126.20 +/- 28.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 126      |\n",
      "|    mean_reward      | 126      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 39500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 9749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5267     |\n",
      "|    total_timesteps  | 39918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 9854     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_40000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_40000_steps.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40000, episode_reward=124.60 +/- 22.66\n",
      "Episode length: 124.60 +/- 22.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 125      |\n",
      "|    mean_reward      | 125      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 9874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5331     |\n",
      "|    total_timesteps  | 40406    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 9976     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_40500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_40500_steps.pkl\n",
      "Eval num_timesteps=40500, episode_reward=164.80 +/- 30.66\n",
      "Episode length: 164.80 +/- 30.66\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 165      |\n",
      "|    mean_reward      | 165      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 9999     |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_41000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_41000_steps.pkl\n",
      "Eval num_timesteps=41000, episode_reward=153.40 +/- 27.80\n",
      "Episode length: 153.40 +/- 27.80\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 153      |\n",
      "|    mean_reward      | 153      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0505   |\n",
      "|    n_updates        | 10124    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5454     |\n",
      "|    total_timesteps  | 41107    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 10151    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_41500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_41500_steps.pkl\n",
      "Eval num_timesteps=41500, episode_reward=262.40 +/- 21.15\n",
      "Episode length: 262.40 +/- 21.15\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 262      |\n",
      "|    mean_reward      | 262      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 41500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 10249    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5544     |\n",
      "|    total_timesteps  | 41762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 10315    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_42000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_42000_steps.pkl\n",
      "Eval num_timesteps=42000, episode_reward=141.60 +/- 22.48\n",
      "Episode length: 141.60 +/- 22.48\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 142      |\n",
      "|    mean_reward      | 142      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 10374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5606     |\n",
      "|    total_timesteps  | 42173    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 10418    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_42500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_42500_steps.pkl\n",
      "Eval num_timesteps=42500, episode_reward=200.40 +/- 31.57\n",
      "Episode length: 200.40 +/- 31.57\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 200      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 42500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 10499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5678     |\n",
      "|    total_timesteps  | 42582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0802   |\n",
      "|    n_updates        | 10520    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_43000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_43000_steps.pkl\n",
      "Eval num_timesteps=43000, episode_reward=180.20 +/- 49.62\n",
      "Episode length: 180.20 +/- 49.62\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 180      |\n",
      "|    mean_reward      | 180      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 10624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5758     |\n",
      "|    total_timesteps  | 43147    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 10661    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_43500_steps.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_43500_steps.pkl\n",
      "Eval num_timesteps=43500, episode_reward=271.00 +/- 33.09\n",
      "Episode length: 271.00 +/- 33.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 271      |\n",
      "|    mean_reward      | 271      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 43500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 10749    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5835     |\n",
      "|    total_timesteps  | 43583    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00894  |\n",
      "|    n_updates        | 10770    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_44000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_44000_steps.pkl\n",
      "Eval num_timesteps=44000, episode_reward=110.80 +/- 0.75\n",
      "Episode length: 110.80 +/- 0.75\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 111      |\n",
      "|    mean_reward      | 111      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 10874    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5897     |\n",
      "|    total_timesteps  | 44086    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 10896    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5920     |\n",
      "|    total_timesteps  | 44450    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00773  |\n",
      "|    n_updates        | 10987    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_44500_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_44500_steps.pkl\n",
      "Eval num_timesteps=44500, episode_reward=221.60 +/- 38.30\n",
      "Episode length: 221.60 +/- 38.30\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 222      |\n",
      "|    mean_reward      | 222      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 44500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.00826  |\n",
      "|    n_updates        | 10999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5990     |\n",
      "|    total_timesteps  | 44876    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 11093    |\n",
      "----------------------------------\n",
      "Saving model checkpoint to ./checkpoints/dqn_single_single_model_45000_steps.zip\n",
      "Saving model replay buffer checkpoint to ./checkpoints/dqn_single_single_model_replay_buffer_45000_steps.pkl\n",
      "Eval num_timesteps=45000, episode_reward=197.80 +/- 40.79\n",
      "Episode length: 197.80 +/- 40.79\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 198      |\n",
      "|    mean_reward      | 198      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0006   |\n",
      "|    loss             | 0.0421   |\n",
      "|    n_updates        | 11124    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1ce317f9f40>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Começa o treinamento\n",
    "model.learn(total_timesteps=45000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_11700\\830487098.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self._driver = webdriver.Chrome(executable_path=self.chromedriver_path,options=_chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Total Reward for episode 0 is 212\n",
      "Total Reward for episode 1 is 161\n",
      "Total Reward for episode 2 is 163\n",
      "Total Reward for episode 3 is 163\n",
      "Total Reward for episode 4 is 159\n"
     ]
    }
   ],
   "source": [
    "test_env = WebGame()\n",
    "model = DQN('CnnPolicy', test_env, tensorboard_log=LOG_DIR, verbose=2, buffer_size=12000, \n",
    "        learning_starts=500, policy_kwargs=dict(normalize_images=False))\n",
    "model.load('checkpoints/best_model') \n",
    "\n",
    "for episode in range(5): \n",
    "    obs = test_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = test_env.step(action)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cddf22ec37e05a39\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cddf22ec37e05a39\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/DQN_23/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9105c753ba2e810590fbe03dc7a47b222fde04124da1bb9f952ac899bb56b210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
